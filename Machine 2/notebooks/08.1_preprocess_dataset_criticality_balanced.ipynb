{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .title {\n",
    "        font-weight: 'bold';\n",
    "    }\n",
    "</style>\n",
    "\n",
    "# <span class=\"title\">08.1 - Création du dataset de données traitées pour entrainement </br> avec criticités équilibrées</span>\n",
    "(sans encodage, ni normalisation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère 1 csv :\n",
    "\n",
    "- dataset_for_training.csv : analyse et nettoyage des variables explicatives\n",
    "\n",
    "Etapes : \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport # pip install ydata_profiling ipywidgets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to datasets\n",
    "path = '../data/'\n",
    "data = 'dataset_for_preprocess_criticality_balanced_07.1.csv'\n",
    "save_csv = '../data/dataset_for_training_criticality_balanced_08.1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(os.path.join(path, data), header=0, parse_dates=True, index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Analyse des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remise à zero des index\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes de metrics\n",
    "# metrics_cols = [\n",
    "#     'status', \n",
    "#     'source_events', \n",
    "#     'timestamp', \n",
    "#     'criticality_events', \n",
    "#     'name_modules', \n",
    "#     'type_modules',\n",
    "#     'generation_modules', \n",
    "#     'value_counters_modules', \n",
    "#     'name_counters_modules',\n",
    "#     'name_connected_operators',\n",
    "#     'level_connected_operators',\n",
    "#     'varnishLevelsTargetvolume',\n",
    "#     'varnishLevelsTotalvolume'\n",
    "#     ]\n",
    "metrics_cols = [\n",
    "    'timestamp', \n",
    "    'identification_events', \n",
    "    'index',\n",
    "    ]\n",
    "df.drop(columns=metrics_cols, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes en doublon entre job_events et jobs\n",
    "job_events_cols = [\n",
    "    'bars_event',\n",
    "    'paperWidth_event', \n",
    "    'paperHeight_event',\n",
    "    'varnishConsumptionVarnish_3d_event'\n",
    "    ]\n",
    "df.drop(columns=job_events_cols, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes de variables catégorielles\n",
    "cat_cols = [\n",
    "    'operator_level', \n",
    "    'operator',\n",
    "    'paperName', \n",
    "    'jobState',\n",
    "    'jobId'\n",
    "   ]\n",
    "df.drop(columns=cat_cols, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes datetime et ajout d'une colonne duration\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])\n",
    "# Calculer la différence de temps entre les deux colonnes\n",
    "df['duration'] = (df['ended_at'] - df['started_at']).dt.total_seconds()\n",
    "df.drop(columns=['started_at', 'ended_at'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supression des colonnes dont les valeurs sont constantes\n",
    "contstant_cols = ['dithering','speedTensionIn_ifoil']\n",
    "df.drop(columns=contstant_cols, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .important {color: #A5EF6E;}\n",
    "    .purple { color: #EF6EE9;}\n",
    "</style>\n",
    "\n",
    "Données disponibles au démarrage d'un job :\n",
    "- <span class='important'>1  thumbnail* : chemin vignette projet</span>\n",
    "- 2  total_copies : nombre de copies imprimées\n",
    "- 3  started_at : date de début\n",
    "- 4  ended_at : date de fin\n",
    "- <span class='important'>5  machineId* : identifiant machine</span>\n",
    "- 6  speed : vitesse d'impression\n",
    "- 7  operator : opérateur\n",
    "- 8  operator_level : niveau de l'opérateur\n",
    "- 9  first_page_image_path_on_machine* : chemin de l'image\n",
    "- 10 paperHeight : hauteur du substrat\n",
    "- 11 paperWidth : largeur du substrat\n",
    "- 12 paperName : appelation du substrat\n",
    "- <span class='important'>13 paperThickness* : épaisseur du substrat (valeur unique à 0)</span>\n",
    "- 14 id_on_machine : identifiant unique du travail d'impression\n",
    "- 15 total_copies_requested : nombre de copies demandées\n",
    "- <span class='important'>16 job_thumbnail_id* : identifiant de vignette image</span>\n",
    "- 17 uses_ifoil : impression utilisant de la dorure\n",
    "- <span class='important'>18 uses_iper* : impression nécéssitant l'iper (valeur unique à True)</span>\n",
    "- 19 scanner_mode : niveau de config du scanner\n",
    "- 20 iper_bvar_count : compteur <span class='purple'># TODO vérifier la fusion notebook 06</span>\n",
    "- 21 varnishConsumptionVarnish_3d : consommation de vernis en 3d\n",
    "- <span class='important'>22 varnishConsumptionVarnish_2d* : consommation de vernis en 2d</span>\n",
    "\n",
    "<span class='important'> *\\*variables déjà supprimées dans le notebook 05 ou 06*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonnes à conserver dispos dans jobs\n",
    "jobs_cols_to_keep = [\n",
    "    'duration',\n",
    "    'total_copies',\n",
    "    'speed',\n",
    "    'paperHeight_job', \n",
    "    'paperWidth_job', \n",
    "    'total_copies_requested',\n",
    "    'ifoil',\n",
    "    'scanner_mode', \n",
    "    'bars_job', # TODO vérifier les valeurs de la variable d'origine iper_bvar_count\n",
    "    'varnishConsumptionVarnish_3d_job'\n",
    "    ]\n",
    "# colonnes à conserver dispos dans job events avec le tag start\n",
    "jobevents_cols_to_keep = [\n",
    "    'LED',\n",
    "    'drops', \n",
    "    'speed_ifoil',\n",
    "    'optifoil_ifoil', \n",
    "    'stampAreas_ifoil',\n",
    "    'heater1Enabled_ifoil', \n",
    "    'heater1Temperature_ifoil',\n",
    "    'x_imageLayout',\n",
    "    'y_imageLayout', \n",
    "    'power_irDryers', \n",
    "    'power_uvDryers',\n",
    "    'leftMargin_remoteScannerRegistration',\n",
    "    'redScore_gridMode_remoteScannerRegistration',\n",
    "    'redScore_cropmarksMode_remoteScannerRegistration',\n",
    "    'redScore_fullScannerMode_remoteScannerRegistration',\n",
    "    'blueScore_fullScannerMode_remoteScannerRegistration',\n",
    "    'greenScore_fullScannerMode_remoteScannerRegistration',\n",
    "    'mode_remoteScannerRegistration'\n",
    "    ]\n",
    "# colonnes à conserver pour la prédiction\n",
    "metrics_cols_to_keep = ['criticality_events']\n",
    "\n",
    "# fusion des listes de colonnes à conserver\n",
    "cols_to_keep = jobs_cols_to_keep + jobevents_cols_to_keep + metrics_cols_to_keep\n",
    "\n",
    "# dataframe des variables conservées\n",
    "df_to_encode = df[cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_encode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_encode.drop(columns=['stampAreas_ifoil', 'total_copies', 'mode_remoteScannerRegistration'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_encode.criticality_events.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_encode.to_csv(save_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
