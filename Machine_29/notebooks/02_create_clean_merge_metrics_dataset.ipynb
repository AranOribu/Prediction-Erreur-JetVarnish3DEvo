{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Creation d'un dataset des données nettoyées de metrics (après fractionnement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère :\n",
    "\n",
    "- 1 fichier csv \"merge_clean_metrics_dataset.csv\"\n",
    "\n",
    "Etapes de nettoyage :\n",
    "\n",
    "- Suppression des colonnes n'ayant que des valeurs nulles\n",
    "\n",
    "- Suppression des colonnes avec informations redondantes (identification=message_events) ou inutiles (id de message)\n",
    "\n",
    "- Conversion des types de colonnes avec le type de valeurs\n",
    "\n",
    "- Remplacement des valeurs nulles\n",
    "\n",
    "- Encodage des codes d'identification en chaine de caractères (maj du metrics_events_dict.json) et de la criticité"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to raw metrics dataset\n",
    "source_csv = '../data/metrics/raw_merge_metrics_dataset.csv'\n",
    "# target path to save metrics dictionnaire\n",
    "save_json ='../data/metrics/metrics_events_dict.json'\n",
    "# target path to save merge raw metrics dataset\n",
    "save_csv = '../data/metrics/clean_merge_metrics_dataset.csv'\n",
    "encoded_save_csv = '../data/metrics/encoded_clean_merge_metrics_dataset.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 761371 entries, 0 to 761370\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   id                         761371 non-null  int64  \n",
      " 1   source_events              30316 non-null   object \n",
      " 2   message_events             30295 non-null   object \n",
      " 3   timestamp_events           30316 non-null   object \n",
      " 4   criticality_events         30316 non-null   object \n",
      " 5   identification_events      30316 non-null   object \n",
      " 6   sn_modules                 0 non-null       float64\n",
      " 7   name_modules               761371 non-null  object \n",
      " 8   type_modules               761371 non-null  object \n",
      " 9   generation_modules         505644 non-null  object \n",
      " 10  name_counters_modules      761371 non-null  object \n",
      " 11  value_counters_modules     761371 non-null  int64  \n",
      " 12  name_connected_operators   761371 non-null  object \n",
      " 13  level_connected_operators  761371 non-null  object \n",
      " 14  status                     761371 non-null  object \n",
      " 15  created_at                 761371 non-null  object \n",
      " 16  varnishLevelsTargetvolume  761371 non-null  float64\n",
      " 17  varnishLevelsTotalvolume   761371 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(13)\n",
      "memory usage: 104.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(Path(source_csv), index_col=0)\n",
    "# réindexation à 0\n",
    "df.reset_index(level=None, drop=True, inplace=True, col_level=0, col_fill='')\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Selection des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes ne contenant que des valeurs nulles\n",
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les colonnes doublons (message=identification)\n",
    "df = df.drop(['id', 'message_events'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on converti les float en entier 64\n",
    "df.varnishLevelsTargetvolume = pd.to_numeric(df.varnishLevelsTargetvolume).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 761371 entries, 0 to 761370\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   source_events              30316 non-null   object\n",
      " 1   timestamp_events           30316 non-null   object\n",
      " 2   criticality_events         30316 non-null   object\n",
      " 3   identification_events      30316 non-null   object\n",
      " 4   name_modules               761371 non-null  object\n",
      " 5   type_modules               761371 non-null  object\n",
      " 6   generation_modules         505644 non-null  object\n",
      " 7   name_counters_modules      761371 non-null  object\n",
      " 8   value_counters_modules     761371 non-null  int64 \n",
      " 9   name_connected_operators   761371 non-null  object\n",
      " 10  level_connected_operators  761371 non-null  object\n",
      " 11  status                     761371 non-null  object\n",
      " 12  created_at                 761371 non-null  object\n",
      " 13  varnishLevelsTargetvolume  761371 non-null  int64 \n",
      " 14  varnishLevelsTotalvolume   761371 non-null  int64 \n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 87.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Colonne 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on renomme la colonne timestamp_events\n",
    "df = df.rename(columns={'timestamp_events':'timestamp'})\n",
    "# on remplace des valeurs maquantes de timestamp par celle de created_at\n",
    "df.timestamp = df.timestamp.fillna(df['created_at'])\n",
    "# on converti les valeur en datetim\n",
    "df.timestamp = pd.to_datetime(df.timestamp, utc=True)\n",
    "# on supprime la colonne doublon (created_at=tiemstamp)\n",
    "df = df.drop(['created_at'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Colonne 'identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['407', '330', '332', '376', '333', '391', '480', '430', nan, '313',\n",
       "       '331', '384', '358', '377', '356', '334', '454', '355', '357',\n",
       "       '381', 'iFoil communication error', '320', '383', '354', '352',\n",
       "       'Kernel_Error', '417', '466', '445', '405',\n",
       "       'RCB communication error', '311', '321', '386', '446', '350',\n",
       "       '372', '314', '385', '440', '345', '346', '0', '380', '371', '388',\n",
       "       '325', '447', '406', '453', '344', '343', '451', '460', '408',\n",
       "       '382', '328', '416', '387', '389', '418'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs nulles par des 0\n",
    "df.identification_events = df.identification_events.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iFoil communication error': 1000,\n",
       " 'Kernel_Error': 1001,\n",
       " 'RCB communication error': 1002}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on encode les valeurs du type 'str' avec un code\n",
    "events_id = []\n",
    "str_code_dict = {}\n",
    "str_code = 1000\n",
    "for id in list(df['identification_events'].unique()) :\n",
    "    try:\n",
    "        events_id.append(int(id))\n",
    "    except ValueError:\n",
    "        str_code_dict[id] = str_code\n",
    "        events_id.append(str_code)\n",
    "        str_code += 1\n",
    "str_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_str_code_dict = {v: k for k, v in str_code_dict.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['identification encoded'] = inv_str_code_dict\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "df.identification_events = df.identification_events.replace(str_code_dict)\n",
    "# on converti toutes les valeurs en entier\n",
    "df.identification_events = pd.to_numeric(df.identification_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 407,  330,  332,  376,  333,  391,  480,  430,    0,  313,  331,\n",
       "        384,  358,  377,  356,  334,  454,  355,  357,  381, 1000,  320,\n",
       "        383,  354,  352, 1001,  417,  466,  445,  405, 1002,  311,  321,\n",
       "        386,  446,  350,  372,  314,  385,  440,  345,  346,  380,  371,\n",
       "        388,  325,  447,  406,  453,  344,  343,  451,  460,  408,  382,\n",
       "        328,  416,  387,  389,  418], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Encodage des labels 'criticality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "encoded_df.criticality_events = encoded_df.criticality_events.fillna(\"UNDEFINED\")\n",
    "criticality = {'UNDEFINED': 0, 'INFO': 1, 'WARNING': 2, 'ERROR':3}\n",
    "encoded_df.criticality_events.replace(criticality, inplace=True)\n",
    "encoded_df.criticality_events = pd.to_numeric(encoded_df.criticality_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_criticality = {v: k for k, v in criticality.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['criticality encoded'] = inv_criticality\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe avant encodage\n",
    "df.to_csv(path_or_buf=Path(save_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-11-03 08:43:16.808000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>407</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>31185</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>1386</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-11-03 08:43:16.808000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>407</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>79566</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>1386</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2022-11-03 08:43:16.746000+00:00</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>407</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>308536</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>1386</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                        timestamp criticality_events  \\\n",
       "0         iFoil 2022-11-03 08:43:16.808000+00:00               INFO   \n",
       "1         iFoil 2022-11-03 08:43:16.808000+00:00               INFO   \n",
       "2           PLC 2022-11-03 08:43:16.746000+00:00            WARNING   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    407         iFoil L            iFoil             Gen. 2   \n",
       "1                    407         iFoil L            iFoil             Gen. 2   \n",
       "2                    407  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   31185                     User   \n",
       "1  Foiled Pages Counter                   79566                     User   \n",
       "2    3D Varnish Counter                  308536                     User   \n",
       "\n",
       "  level_connected_operators   status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator  WARNING                       1386   \n",
       "1                  Operator  WARNING                       1386   \n",
       "2                  Operator  WARNING                       1386   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                     18000  \n",
       "1                     18000  \n",
       "2                     18000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe après encodage\n",
    "encoded_df.to_csv(path_or_buf=Path(encoded_save_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2315c9af7dedaeb0b2bf51504304a927c605b523f04dad98936c50abe500b408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
