{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07.1- Création d'un dataset de la fusion des datasets de clean metrics et clean jobs/job_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère 1 csv :\n",
    "\n",
    "- dataset_for_preprocess.csv qui fusionne les données du dataset de metrics et jobs/job_events\n",
    "\n",
    "Etapes : \n",
    "\n",
    "B) Import des datasets : \n",
    "\n",
    "- metrics est quasi-brut (la colonne events est fractionnée et tous les identifiants d'évènements sont des nombres)\n",
    "\n",
    "- jobs (le dataset fusionné des données de jobs et job_events) dont chaque ligne est un job, un job est unique et il a un début et une fin\n",
    "\n",
    "C) Réduction du dataset jobs et réductions succesives du dataset metrics (les lignes évènements avec certains identifiants)\n",
    "\n",
    "D) Concaténation des datasets jobs et metrics (suppression des lignes inutiles : toutes celles de jobs et metrics si aucun jobId associé)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to datasets\n",
    "path = '../data/'\n",
    "metrics = 'metrics/clean_merge_metrics_dataset.csv'\n",
    "jobs = 'jobs/merge_raw_jobs_and_clean_jobevents_dataset.csv'\n",
    "\n",
    "save_csv = '../data/dataset_for_preprocess_criticality_balanced_07.1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITICALITY_NULL = 'NO_EVENT'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics dataset shape (178761, 14)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "metrics_df = pd.read_csv(os.path.join(path, metrics), index_col=0)\n",
    "print(f'metrics dataset shape {metrics_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne timestamp contient-elle des valeurs en double ?\n",
    "metrics_df['timestamp'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-02 13:39:57.321000+00:00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62681\n"
     ]
    }
   ],
   "source": [
    "# Grouper les lignes par la colonne \"timestamp\" et obtenir les index correspondants\n",
    "groupes = metrics_df.groupby('timestamp').groups\n",
    "print(len(groupes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2024-01-02 13:39:59.075000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>52108</td>\n",
       "      <td>JAN</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>40490</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2024-01-02 13:39:59.075000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>132061</td>\n",
       "      <td>JAN</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>40490</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2024-01-02 13:39:58.986000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>36042</td>\n",
       "      <td>JAN</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>40490</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                         timestamp criticality_events  \\\n",
       "0         iFoil  2024-01-02 13:39:59.075000+00:00               INFO   \n",
       "1         iFoil  2024-01-02 13:39:59.075000+00:00               INFO   \n",
       "2           PLC  2024-01-02 13:39:58.986000+00:00               INFO   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    391         iFoil L            iFoil             Gen. 2   \n",
       "1                    391         iFoil L            iFoil             Gen. 2   \n",
       "2                    391  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   52108                      JAN   \n",
       "1  Foiled Pages Counter                  132061                      JAN   \n",
       "2    3D Varnish Counter                   36042                      JAN   \n",
       "\n",
       "  level_connected_operators   status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator  WARNING                      40490   \n",
       "1                  Operator  WARNING                      40490   \n",
       "2                  Operator  WARNING                      40490   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                    100000  \n",
       "1                    100000  \n",
       "2                    100000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs dataset shape (1139, 36)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "jobs_df = pd.read_csv(os.path.join(path, jobs), index_col=0)\n",
    "print(f'jobs dataset shape {jobs_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne started_at contient-elle des valeurs en double ?\n",
    "jobs_df['started_at'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-02 13:41:07.413000+00:00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df['started_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>paperHeight_job</th>\n",
       "      <th>paperWidth_job</th>\n",
       "      <th>scanner_mode</th>\n",
       "      <th>bars_job</th>\n",
       "      <th>copies_per_run</th>\n",
       "      <th>jobId</th>\n",
       "      <th>total_copies_requested</th>\n",
       "      <th>LED</th>\n",
       "      <th>...</th>\n",
       "      <th>speed</th>\n",
       "      <th>power_irDryers</th>\n",
       "      <th>power_uvDryers</th>\n",
       "      <th>leftMargin_remoteScannerRegistration</th>\n",
       "      <th>blueScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>greenScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>mode_remoteScannerRegistration</th>\n",
       "      <th>jobState</th>\n",
       "      <th>total_copies</th>\n",
       "      <th>varnishConsumptionVarnish_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02 13:41:07.413000+00:00</td>\n",
       "      <td>2024-01-02 13:42:21.613000+00:00</td>\n",
       "      <td>520</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1704202867</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 14:07:56.422000+00:00</td>\n",
       "      <td>2024-01-02 14:13:05.397000+00:00</td>\n",
       "      <td>520</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1704204476</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02 14:26:11.497000+00:00</td>\n",
       "      <td>2024-01-02 14:29:28.946000+00:00</td>\n",
       "      <td>520</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1704205571</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>CANCELED</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         started_at                          ended_at  \\\n",
       "0  2024-01-02 13:41:07.413000+00:00  2024-01-02 13:42:21.613000+00:00   \n",
       "1  2024-01-02 14:07:56.422000+00:00  2024-01-02 14:13:05.397000+00:00   \n",
       "2  2024-01-02 14:26:11.497000+00:00  2024-01-02 14:29:28.946000+00:00   \n",
       "\n",
       "   paperHeight_job  paperWidth_job  scanner_mode  bars_job  copies_per_run  \\\n",
       "0              520             740             1         2               0   \n",
       "1              520             740             1         2               0   \n",
       "2              520             740             1         2               0   \n",
       "\n",
       "        jobId  total_copies_requested  LED  ... speed  power_irDryers  \\\n",
       "0  1704202867                     350   10  ...   500              45   \n",
       "1  1704204476                     350   10  ...   500              45   \n",
       "2  1704205571                     350   10  ...   500              45   \n",
       "\n",
       "   power_uvDryers  leftMargin_remoteScannerRegistration  \\\n",
       "0             100                                     0   \n",
       "1             100                                     0   \n",
       "2             100                                     0   \n",
       "\n",
       "  blueScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 16    \n",
       "1                                                 16    \n",
       "2                                                 16    \n",
       "\n",
       "  greenScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 16     \n",
       "1                                                 16     \n",
       "2                                                 16     \n",
       "\n",
       "   mode_remoteScannerRegistration  jobState  total_copies  \\\n",
       "0                               1   SUCCESS             0   \n",
       "1                               1   SUCCESS             0   \n",
       "2                               1  CANCELED             0   \n",
       "\n",
       "  varnishConsumptionVarnish_3d  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tailles des datasets sont déséquilibrés :\n",
    "\n",
    "- 3510431 lignes pour metrics\n",
    "\n",
    "- 16295 lignes pour jobs\n",
    "\n",
    "Les dates de début sont différentes :\n",
    "\n",
    "- '2022-04-15 05:55:06.678000+00:00' pour metrics\n",
    "\n",
    "- '2021-06-18 09:22:46.866000+00:00' pour jobs\n",
    "\n",
    "Le dataset metrics compte 1242037 doublons pour la colonne timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Equilibrage des jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Réduction de jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concordance des données de temps dans un même cadre\n",
    "jobs_reduced = jobs_df[jobs_df.started_at > metrics_df.timestamp.min()]\n",
    "jobs_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Réduction de metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs de criticité nulles par 'UNDEFINED'\n",
    "# ce sont le messages de metrics qui n'ont pas d'évènements\n",
    "metrics_df['criticality_events'] = metrics_df['criticality_events'].fillna(CRITICALITY_NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_EVENT    174885\n",
       "INFO          2921\n",
       "WARNING        539\n",
       "ERROR          416\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_df['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de lignes en criticité 'ERROR' : 416\n"
     ]
    }
   ],
   "source": [
    "# on détermine le nombre de lignes ERROR\n",
    "errors = metrics_df['criticality_events'][metrics_df['criticality_events'] == 'ERROR'].count()\n",
    "print(f\"Le nombre de lignes en criticité 'ERROR' : {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def balance_dataframe_by_criticality(df, criticality, n):\n",
    "#     # on filtre les lignes du df qui ont la valeur criticality dans la colonne 'criticality_events'\n",
    "#     df_criticality = df[df['criticality_events'] == criticality]\n",
    "#     # on selectionne un nombre aléatoire de lignes\n",
    "#     df_criticality_sample = df_criticality.sample(n=n)\n",
    "#     # on stoke les index des lignes du df qui ne sont pas dans le sample\n",
    "#     index_to_delete = df_criticality[~df_criticality.index.isin(df_criticality_sample.index)].index\n",
    "#     # suppression des lignes exclu du sample\n",
    "#     return df.drop(index_to_delete)\n",
    "\n",
    "def balance_dataframe_by_criticality(df, criticality, n):\n",
    "    # Filtre les lignes du df avec la valeur de criticality dans la colonne 'criticality_events'\n",
    "    df_criticality = df[df['criticality_events'] == criticality]\n",
    "\n",
    "    # Obtient le nombre de lignes dans df_criticality\n",
    "    taille_population = df_criticality.shape[0]\n",
    "\n",
    "    # Assurez-vous que n est inférieur ou égal à la taille de la population\n",
    "    n = min(n, taille_population)\n",
    "\n",
    "    # Sélectionne un nombre aléatoire de lignes\n",
    "    df_criticality_sample = df_criticality.sample(n=n)\n",
    "\n",
    "    # Stocke les index des lignes du df qui ne sont pas dans le sample\n",
    "    index_to_delete = df_criticality[~df_criticality.index.isin(df_criticality_sample.index)].index\n",
    "\n",
    "    # Suppression des lignes exclues du sample\n",
    "    return df.drop(index_to_delete)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### par criticité UNDEFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = balance_dataframe_by_criticality(metrics_df, CRITICALITY_NULL, errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### par criticité INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = balance_dataframe_by_criticality(metrics_df, 'INFO', errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### par criticité WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLE       863\n",
       "WARNING    590\n",
       "ERR        334\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = balance_dataframe_by_criticality(metrics_df, 'WARNING', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO        416\n",
       "ERROR       416\n",
       "WARNING     416\n",
       "NO_EVENT    416\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Création du datatset pour le pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_reduced = metrics_df\n",
    "metrics_reduced['jobId'] = 0\n",
    "metrics_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Association d'un jobId à une ligne metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allan\\AppData\\Local\\Temp\\ipykernel_17556\\1041892598.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe1[cols_to_convert] = dataframe1[cols_to_convert].apply(pd.to_datetime)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>jobId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-02 13:41:07.413000+00:00</td>\n",
       "      <td>2024-01-02 13:42:21.613000+00:00</td>\n",
       "      <td>1704202867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-02 14:07:56.422000+00:00</td>\n",
       "      <td>2024-01-02 14:13:05.397000+00:00</td>\n",
       "      <td>1704204476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-02 14:26:11.497000+00:00</td>\n",
       "      <td>2024-01-02 14:29:28.946000+00:00</td>\n",
       "      <td>1704205571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       started_at                         ended_at  \\\n",
       "0      0 2024-01-02 13:41:07.413000+00:00 2024-01-02 13:42:21.613000+00:00   \n",
       "1      1 2024-01-02 14:07:56.422000+00:00 2024-01-02 14:13:05.397000+00:00   \n",
       "2      2 2024-01-02 14:26:11.497000+00:00 2024-01-02 14:29:28.946000+00:00   \n",
       "\n",
       "        jobId  \n",
       "0  1704202867  \n",
       "1  1704204476  \n",
       "2  1704205571  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 1 \n",
    "# avec les intervalles de temps\n",
    "dataframe1 = jobs_reduced[['started_at', 'ended_at', 'jobId']]\n",
    "# conversion des colonnes au format datetime\n",
    "cols_to_convert = ['started_at', 'ended_at']\n",
    "dataframe1[cols_to_convert] = dataframe1[cols_to_convert].apply(pd.to_datetime)\n",
    "dataframe1 = dataframe1.sort_values('started_at')\n",
    "dataframe1 = dataframe1.reset_index()\n",
    "dataframe1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>jobId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346</td>\n",
       "      <td>2024-01-02 13:41:28.848000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347</td>\n",
       "      <td>2024-01-02 13:42:18.433000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>2024-01-02 13:43:55.267000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        timestamp criticality_events  \\\n",
       "0    346 2024-01-02 13:41:28.848000+00:00              ERROR   \n",
       "1    347 2024-01-02 13:42:18.433000+00:00              ERROR   \n",
       "2    348 2024-01-02 13:43:55.267000+00:00              ERROR   \n",
       "\n",
       "   identification_events  jobId  \n",
       "0                    417      0  \n",
       "1                    387      0  \n",
       "2                    354      0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 2 \n",
    "# avec les valeurs de date\n",
    "dataframe2 = pd.DataFrame({\n",
    "    'timestamp': metrics_reduced['timestamp'].values,\n",
    "    'criticality_events': metrics_reduced['criticality_events'].values,\n",
    "    'identification_events': metrics_reduced['identification_events'].values,\n",
    "    'jobId': 0\n",
    "}, index=None)\n",
    "# conversion des colonnes au format datetime\n",
    "dataframe2['timestamp'] = pd.to_datetime(dataframe2['timestamp'])\n",
    "dataframe2 = dataframe2.sort_values('timestamp')\n",
    "dataframe2 = dataframe2.reset_index()\n",
    "dataframe2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ job index 1000 = time 40.67697310447693]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# début du temps d'execution de la cellule\n",
    "start = time.time()\n",
    "\n",
    "# Parcours chaque ligne de job\n",
    "for index1, row1 in dataframe1.iterrows():\n",
    "    # creation des variables\n",
    "    job_starts = row1.started_at.tz_localize(None)\n",
    "    job_ends = row1.ended_at.tz_localize(None)\n",
    "\n",
    "    # mois de référence\n",
    "    month = job_starts.month\n",
    "    if month != job_ends.month :\n",
    "        dataframe2_bymonth = dataframe2[(dataframe2['timestamp'].dt.month == month) | (dataframe2['timestamp'].dt.month == job_ends.month) & (dataframe2['jobId'] == 0)]\n",
    "        dataframe2_by_month = dataframe2_by_month.sort_values('timestamp')\n",
    "    else :\n",
    "        dataframe2_by_month = dataframe2[(dataframe2['timestamp'].dt.month == month) & (dataframe2['jobId'] == 0)]\n",
    "        dataframe2_by_month = dataframe2_by_month.sort_values('timestamp')\n",
    "\n",
    "    for index2, row2 in dataframe2_by_month.iterrows():\n",
    "        # creation des variables\n",
    "        metrics_timestamp = row2['timestamp'].tz_localize(None)\n",
    "        # si le timestamp de la lignes de row2 de metrics est compris dans l'intervalle de temps du job de row1\n",
    "        if metrics_timestamp >= job_starts :\n",
    "            if metrics_timestamp <= job_ends :\n",
    "                dataframe2.loc[index2, 'jobId'] = dataframe1.loc[index1, 'jobId']\n",
    "    # # avant de passer à la row1 suivant\n",
    "    # # on affiche l'index1 toutes les 1000 lignes et son temps d'execution\n",
    "    print(f'[ job index {index1} = time {time.time() - start}]') if index1 % 1000 == 0 and index1 != 0 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WARNING     282\n",
       "INFO        199\n",
       "NO_EVENT    163\n",
       "ERROR       134\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticality_events pour les lignes du dataframe2 (metrics_df) qui ont été associées à un jobId\n",
    "dataframe2[dataframe2['jobId'] != 0]['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de ligne de metrics : 1664 (dont 778 avec un jobId associé)\n"
     ]
    }
   ],
   "source": [
    "print(f'Nombre de ligne de metrics : {dataframe2.shape[0]} (dont {dataframe2[dataframe2.jobId != 0].shape[0]} avec un jobId associé)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Fusion des données de job avec les lignes de metrics (dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = jobs_reduced.merge(dataframe2, on='jobId')\n",
    "merged_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fusion on jobId permet de ne conserver que les lignes de metrics qui ont un jobId."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Equilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de lignes en criticité 'ERROR' : 134\n"
     ]
    }
   ],
   "source": [
    "# on détermine le nombre de lignes ERROR\n",
    "merge_df_errors = merged_df['criticality_events'][merged_df['criticality_events'] == 'ERROR'].count()\n",
    "print(f\"Le nombre de lignes en criticité 'ERROR' : {merge_df_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réduction des autres classes par rapport à ERROR\n",
    "merged_df = balance_dataframe_by_criticality(merged_df, CRITICALITY_NULL, merge_df_errors)\n",
    "merged_df = balance_dataframe_by_criticality(merged_df, 'WARNING', merge_df_errors)\n",
    "merged_df = balance_dataframe_by_criticality(merged_df, 'INFO', merge_df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR       134\n",
       "INFO        134\n",
       "WARNING     134\n",
       "NO_EVENT    134\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité pour les lignes du dataframe2 (metrics_df) qui ont été associées à un jobId\n",
    "merged_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(path_or_buf=save_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
