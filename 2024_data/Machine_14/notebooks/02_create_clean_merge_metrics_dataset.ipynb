{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Creation d'un dataset des données nettoyées de metrics (après fractionnement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère :\n",
    "\n",
    "- 1 fichier csv \"merge_clean_metrics_dataset.csv\"\n",
    "\n",
    "Etapes de nettoyage :\n",
    "\n",
    "- Suppression des colonnes n'ayant que des valeurs nulles\n",
    "\n",
    "- Suppression des colonnes avec informations redondantes (identification=message_events) ou inutiles (id de message)\n",
    "\n",
    "- Conversion des types de colonnes avec le type de valeurs\n",
    "\n",
    "- Remplacement des valeurs nulles\n",
    "\n",
    "- Encodage des codes d'identification en chaine de caractères (maj du metrics_events_dict.json) et de la criticité"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to raw metrics dataset\n",
    "source_csv = '../data/metrics/raw_merge_metrics_dataset.csv'\n",
    "# target path to save metrics dictionnaire\n",
    "save_json ='../data/metrics/metrics_events_dict.json'\n",
    "# target path to save merge raw metrics dataset\n",
    "save_csv = '../data/metrics/clean_merge_metrics_dataset.csv'\n",
    "encoded_save_csv = '../data/metrics/encoded_clean_merge_metrics_dataset.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178761 entries, 0 to 178760\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   id                         178761 non-null  int64  \n",
      " 1   source_events              3876 non-null    object \n",
      " 2   message_events             3875 non-null    object \n",
      " 3   timestamp_events           3876 non-null    object \n",
      " 4   criticality_events         3876 non-null    object \n",
      " 5   identification_events      3876 non-null    object \n",
      " 6   sn_modules                 0 non-null       float64\n",
      " 7   name_modules               178761 non-null  object \n",
      " 8   type_modules               178761 non-null  object \n",
      " 9   generation_modules         118900 non-null  object \n",
      " 10  name_counters_modules      178761 non-null  object \n",
      " 11  value_counters_modules     178761 non-null  int64  \n",
      " 12  name_connected_operators   178761 non-null  object \n",
      " 13  level_connected_operators  178761 non-null  object \n",
      " 14  status                     178761 non-null  object \n",
      " 15  created_at                 178761 non-null  object \n",
      " 16  varnishLevelsTargetvolume  178761 non-null  float64\n",
      " 17  varnishLevelsTotalvolume   178761 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(13)\n",
      "memory usage: 24.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(Path(source_csv), index_col=0)\n",
    "# réindexation à 0\n",
    "df.reset_index(level=None, drop=True, inplace=True, col_level=0, col_fill='')\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Selection des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes ne contenant que des valeurs nulles\n",
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les colonnes doublons (message=identification)\n",
    "df = df.drop(['id', 'message_events'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on converti les float en entier 64\n",
    "df.varnishLevelsTargetvolume = pd.to_numeric(df.varnishLevelsTargetvolume).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178761 entries, 0 to 178760\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   source_events              3876 non-null    object\n",
      " 1   timestamp_events           3876 non-null    object\n",
      " 2   criticality_events         3876 non-null    object\n",
      " 3   identification_events      3876 non-null    object\n",
      " 4   name_modules               178761 non-null  object\n",
      " 5   type_modules               178761 non-null  object\n",
      " 6   generation_modules         118900 non-null  object\n",
      " 7   name_counters_modules      178761 non-null  object\n",
      " 8   value_counters_modules     178761 non-null  int64 \n",
      " 9   name_connected_operators   178761 non-null  object\n",
      " 10  level_connected_operators  178761 non-null  object\n",
      " 11  status                     178761 non-null  object\n",
      " 12  created_at                 178761 non-null  object\n",
      " 13  varnishLevelsTargetvolume  178761 non-null  int64 \n",
      " 14  varnishLevelsTotalvolume   178761 non-null  int64 \n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 20.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Colonne 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on renomme la colonne timestamp_events\n",
    "df = df.rename(columns={'timestamp_events':'timestamp'})\n",
    "# on remplace des valeurs maquantes de timestamp par celle de created_at\n",
    "df.timestamp = df.timestamp.fillna(df['created_at'])\n",
    "# on converti les valeur en datetim\n",
    "df.timestamp = pd.to_datetime(df.timestamp, utc=True)\n",
    "# on supprime la colonne doublon (created_at=tiemstamp)\n",
    "df = df.drop(['created_at'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Colonne 'identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['391', '333', '331', '321', '480', '386', nan, '330', '371', '332',\n",
       "       '376', '372', '323', '377', '344', '313', '355', 'Kernel_Error',\n",
       "       '357', '440', '343', '454', '356', '352', '408', '324', '374',\n",
       "       '354', '334', '417', '387', '311', '315', '406', '407', '0', '470',\n",
       "       'RCB communication error', '472', '373', '475', '405', '345',\n",
       "       '445', '358', '460', '453'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs nulles par des 0\n",
    "df.identification_events = df.identification_events.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kernel_Error': 1000, 'RCB communication error': 1001}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on encode les valeurs du type 'str' avec un code\n",
    "events_id = []\n",
    "str_code_dict = {}\n",
    "str_code = 1000\n",
    "for id in list(df['identification_events'].unique()) :\n",
    "    try:\n",
    "        events_id.append(int(id))\n",
    "    except ValueError:\n",
    "        str_code_dict[id] = str_code\n",
    "        events_id.append(str_code)\n",
    "        str_code += 1\n",
    "str_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_str_code_dict = {v: k for k, v in str_code_dict.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['identification encoded'] = inv_str_code_dict\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "df.identification_events = df.identification_events.replace(str_code_dict)\n",
    "# on converti toutes les valeurs en entier\n",
    "df.identification_events = pd.to_numeric(df.identification_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 391,  333,  331,  321,  480,  386,    0,  330,  371,  332,  376,\n",
       "        372,  323,  377,  344,  313,  355, 1000,  357,  440,  343,  454,\n",
       "        356,  352,  408,  324,  374,  354,  334,  417,  387,  311,  315,\n",
       "        406,  407,  470, 1001,  472,  373,  475,  405,  345,  445,  358,\n",
       "        460,  453], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Encodage des labels 'criticality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "encoded_df.criticality_events = encoded_df.criticality_events.fillna(\"UNDEFINED\")\n",
    "criticality = {'UNDEFINED': 0, 'INFO': 1, 'WARNING': 2, 'ERROR':3}\n",
    "encoded_df.criticality_events.replace(criticality, inplace=True)\n",
    "encoded_df.criticality_events = pd.to_numeric(encoded_df.criticality_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_criticality = {v: k for k, v in criticality.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['criticality encoded'] = inv_criticality\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe avant encodage\n",
    "df.to_csv(path_or_buf=Path(save_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2024-01-02 13:39:59.075000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>52108</td>\n",
       "      <td>JAN</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>40490</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2024-01-02 13:39:59.075000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>132061</td>\n",
       "      <td>JAN</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>40490</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2024-01-02 13:39:58.986000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>36042</td>\n",
       "      <td>JAN</td>\n",
       "      <td>Operator</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>40490</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                        timestamp criticality_events  \\\n",
       "0         iFoil 2024-01-02 13:39:59.075000+00:00               INFO   \n",
       "1         iFoil 2024-01-02 13:39:59.075000+00:00               INFO   \n",
       "2           PLC 2024-01-02 13:39:58.986000+00:00               INFO   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    391         iFoil L            iFoil             Gen. 2   \n",
       "1                    391         iFoil L            iFoil             Gen. 2   \n",
       "2                    391  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   52108                      JAN   \n",
       "1  Foiled Pages Counter                  132061                      JAN   \n",
       "2    3D Varnish Counter                   36042                      JAN   \n",
       "\n",
       "  level_connected_operators   status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator  WARNING                      40490   \n",
       "1                  Operator  WARNING                      40490   \n",
       "2                  Operator  WARNING                      40490   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                    100000  \n",
       "1                    100000  \n",
       "2                    100000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe après encodage\n",
    "encoded_df.to_csv(path_or_buf=Path(encoded_save_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2315c9af7dedaeb0b2bf51504304a927c605b523f04dad98936c50abe500b408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
