{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07.1- Création d'un dataset de la fusion des datasets de clean metrics et clean jobs/job_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère 1 csv :\n",
    "\n",
    "- dataset_for_preprocess.csv qui fusionne les données du dataset de metrics et jobs/job_events\n",
    "\n",
    "Etapes : \n",
    "\n",
    "B) Import des datasets : \n",
    "\n",
    "- metrics est quasi-brut (la colonne events est fractionnée et tous les identifiants d'évènements sont des nombres)\n",
    "\n",
    "- jobs (le dataset fusionné des données de jobs et job_events) dont chaque ligne est un job, un job est unique et il a un début et une fin\n",
    "\n",
    "C) Réduction du dataset jobs et réductions succesives du dataset metrics (les lignes évènements avec certains identifiants)\n",
    "\n",
    "D) Concaténation des datasets jobs et metrics (suppression des lignes inutiles : toutes celles de jobs et metrics si aucun jobId associé)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to datasets\n",
    "path = '../data/'\n",
    "metrics = 'metrics/clean_merge_metrics_dataset.csv'\n",
    "jobs = 'jobs/merge_raw_jobs_and_clean_jobevents_dataset.csv'\n",
    "\n",
    "save_csv = '../data/dataset_for_preprocess_criticality_balanced_07.1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITICALITY_NULL = 'NO_EVENT'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics dataset shape (2693836, 14)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "metrics_df = pd.read_csv(os.path.join(path, metrics), index_col=0)\n",
    "print(f'metrics dataset shape {metrics_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne timestamp contient-elle des valeurs en double ?\n",
    "metrics_df['timestamp'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-02 08:28:54.218000+00:00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105867\n"
     ]
    }
   ],
   "source": [
    "# Grouper les lignes par la colonne \"timestamp\" et obtenir les index correspondants\n",
    "groupes = metrics_df.groupby('timestamp').groups\n",
    "print(len(groupes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-11-02 08:28:57.675000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>39968</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>ERR</td>\n",
       "      <td>7553</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-11-02 08:28:57.675000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>39740</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>ERR</td>\n",
       "      <td>7553</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2022-11-02 08:28:57.613000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1734834</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>ERR</td>\n",
       "      <td>7553</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                         timestamp criticality_events  \\\n",
       "0         iFoil  2022-11-02 08:28:57.675000+00:00              ERROR   \n",
       "1         iFoil  2022-11-02 08:28:57.675000+00:00              ERROR   \n",
       "2           PLC  2022-11-02 08:28:57.613000+00:00              ERROR   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    358         iFoil L            iFoil             Gen. 2   \n",
       "1                    358         iFoil L            iFoil             Gen. 2   \n",
       "2                    358  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   39968                     User   \n",
       "1  Foiled Pages Counter                   39740                     User   \n",
       "2    3D Varnish Counter                 1734834                     User   \n",
       "\n",
       "  level_connected_operators status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator    ERR                       7553   \n",
       "1                  Operator    ERR                       7553   \n",
       "2                  Operator    ERR                       7553   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                     18000  \n",
       "1                     18000  \n",
       "2                     18000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs dataset shape (47073, 51)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "jobs_df = pd.read_csv(os.path.join(path, jobs), index_col=0)\n",
    "print(f'jobs dataset shape {jobs_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne started_at contient-elle des valeurs en double ?\n",
    "jobs_df['started_at'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-02-22 09:43:04.487000+00:00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df['started_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_copies_job</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>paperHeight_job</th>\n",
       "      <th>paperWidth_job</th>\n",
       "      <th>scanner_mode</th>\n",
       "      <th>bars_job</th>\n",
       "      <th>varnishConsumptionVarnish_3d_job</th>\n",
       "      <th>run</th>\n",
       "      <th>total_run</th>\n",
       "      <th>...</th>\n",
       "      <th>y_cropmark2_cropmarksMode_remoteScannerRegistration</th>\n",
       "      <th>exposureTime_manualLighting_remoteScannerRegistration</th>\n",
       "      <th>redScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>blueScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>greenScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>enable_specialSubstrate_remoteScannerRegistration</th>\n",
       "      <th>mode_remoteScannerRegistration</th>\n",
       "      <th>jobState</th>\n",
       "      <th>total_copies_event</th>\n",
       "      <th>varnishConsumptionVarnish_3d_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>2022-02-22 09:43:04.487000+00:00</td>\n",
       "      <td>2022-02-22 09:46:07.946000+00:00</td>\n",
       "      <td>470</td>\n",
       "      <td>330</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.414782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>40</td>\n",
       "      <td>4.414782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-02-22 09:47:20.673000+00:00</td>\n",
       "      <td>2022-02-22 09:48:57.474000+00:00</td>\n",
       "      <td>470</td>\n",
       "      <td>330</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.004043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>18</td>\n",
       "      <td>3.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2022-02-22 09:50:14.555000+00:00</td>\n",
       "      <td>2022-02-22 09:51:50.551000+00:00</td>\n",
       "      <td>470</td>\n",
       "      <td>330</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.503964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>15</td>\n",
       "      <td>2.503964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_copies_job                        started_at  \\\n",
       "0                40  2022-02-22 09:43:04.487000+00:00   \n",
       "1                18  2022-02-22 09:47:20.673000+00:00   \n",
       "2                15  2022-02-22 09:50:14.555000+00:00   \n",
       "\n",
       "                           ended_at  paperHeight_job  paperWidth_job  \\\n",
       "0  2022-02-22 09:46:07.946000+00:00              470             330   \n",
       "1  2022-02-22 09:48:57.474000+00:00              470             330   \n",
       "2  2022-02-22 09:51:50.551000+00:00              470             330   \n",
       "\n",
       "   scanner_mode  bars_job  varnishConsumptionVarnish_3d_job  run  total_run  \\\n",
       "0             3         2                          4.414782    0          0   \n",
       "1             3         2                          3.004043    0          0   \n",
       "2             3         2                          2.503964    0          0   \n",
       "\n",
       "   ...  y_cropmark2_cropmarksMode_remoteScannerRegistration  \\\n",
       "0  ...                                                  0     \n",
       "1  ...                                                  0     \n",
       "2  ...                                                  0     \n",
       "\n",
       "   exposureTime_manualLighting_remoteScannerRegistration  \\\n",
       "0                                                100       \n",
       "1                                                100       \n",
       "2                                                100       \n",
       "\n",
       "   redScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                               1500    \n",
       "1                                               1500    \n",
       "2                                               1500    \n",
       "\n",
       "   blueScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 20     \n",
       "1                                                 20     \n",
       "2                                                 20     \n",
       "\n",
       "  greenScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 20     \n",
       "1                                                 20     \n",
       "2                                                 20     \n",
       "\n",
       "   enable_specialSubstrate_remoteScannerRegistration  \\\n",
       "0                                              False   \n",
       "1                                              False   \n",
       "2                                              False   \n",
       "\n",
       "   mode_remoteScannerRegistration  jobState total_copies_event  \\\n",
       "0                               3   SUCCESS                 40   \n",
       "1                               3   SUCCESS                 18   \n",
       "2                               3   SUCCESS                 15   \n",
       "\n",
       "  varnishConsumptionVarnish_3d_event  \n",
       "0                           4.414782  \n",
       "1                           3.004043  \n",
       "2                           2.503964  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tailles des datasets sont déséquilibrés :\n",
    "\n",
    "- 3510431 lignes pour metrics\n",
    "\n",
    "- 16295 lignes pour jobs\n",
    "\n",
    "Les dates de début sont différentes :\n",
    "\n",
    "- '2022-04-15 05:55:06.678000+00:00' pour metrics\n",
    "\n",
    "- '2021-06-18 09:22:46.866000+00:00' pour jobs\n",
    "\n",
    "Le dataset metrics compte 1242037 doublons pour la colonne timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Equilibrage des jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Réduction de jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32118, 51)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concordance des données de temps dans un même cadre\n",
    "jobs_reduced = jobs_df[jobs_df.started_at > metrics_df.timestamp.min()]\n",
    "jobs_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Réduction de metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs de criticité nulles par 'UNDEFINED'\n",
    "# ce sont le messages de metrics qui n'ont pas d'évènements\n",
    "metrics_df['criticality_events'] = metrics_df['criticality_events'].fillna(CRITICALITY_NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_EVENT    2367049\n",
       "INFO         303552\n",
       "ERROR         16860\n",
       "WARNING        6375\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_df['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de lignes en criticité 'ERROR' : 16860\n"
     ]
    }
   ],
   "source": [
    "# on détermine le nombre de lignes ERROR\n",
    "errors = metrics_df['criticality_events'][metrics_df['criticality_events'] == 'ERROR'].count()\n",
    "print(f\"Le nombre de lignes en criticité 'ERROR' : {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def balance_dataframe_by_criticality(df, criticality, n):\n",
    "#     # on filtre les lignes du df qui ont la valeur criticality dans la colonne 'criticality_events'\n",
    "#     df_criticality = df[df['criticality_events'] == criticality]\n",
    "#     # on selectionne un nombre aléatoire de lignes\n",
    "#     df_criticality_sample = df_criticality.sample(n=n)\n",
    "#     # on stoke les index des lignes du df qui ne sont pas dans le sample\n",
    "#     index_to_delete = df_criticality[~df_criticality.index.isin(df_criticality_sample.index)].index\n",
    "#     # suppression des lignes exclu du sample\n",
    "#     return df.drop(index_to_delete)\n",
    "\n",
    "def balance_dataframe_by_criticality(df, criticality, n):\n",
    "    # Filtre les lignes du df avec la valeur de criticality dans la colonne 'criticality_events'\n",
    "    df_criticality = df[df['criticality_events'] == criticality]\n",
    "\n",
    "    # Obtient le nombre de lignes dans df_criticality\n",
    "    taille_population = df_criticality.shape[0]\n",
    "\n",
    "    # Assurez-vous que n est inférieur ou égal à la taille de la population\n",
    "    n = min(n, taille_population)\n",
    "\n",
    "    # Sélectionne un nombre aléatoire de lignes\n",
    "    df_criticality_sample = df_criticality.sample(n=n)\n",
    "\n",
    "    # Stocke les index des lignes du df qui ne sont pas dans le sample\n",
    "    index_to_delete = df_criticality[~df_criticality.index.isin(df_criticality_sample.index)].index\n",
    "\n",
    "    # Suppression des lignes exclues du sample\n",
    "    return df.drop(index_to_delete)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### par criticité UNDEFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = balance_dataframe_by_criticality(metrics_df, CRITICALITY_NULL, errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### par criticité INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = balance_dataframe_by_criticality(metrics_df, 'INFO', errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### par criticité WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = balance_dataframe_by_criticality(metrics_df, 'WARNING', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR       16860\n",
       "INFO        16860\n",
       "NO_EVENT    16860\n",
       "WARNING      6375\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Création du datatset pour le pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56955, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_reduced = metrics_df\n",
    "metrics_reduced['jobId'] = 0\n",
    "metrics_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Association d'un jobId à une ligne metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allan\\AppData\\Local\\Temp\\ipykernel_10828\\1041892598.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe1[cols_to_convert] = dataframe1[cols_to_convert].apply(pd.to_datetime)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>jobId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14955</td>\n",
       "      <td>2022-11-02 08:34:21.469000+00:00</td>\n",
       "      <td>2022-11-02 08:40:14.413000+00:00</td>\n",
       "      <td>1667378061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14956</td>\n",
       "      <td>2022-11-02 08:40:31.774000+00:00</td>\n",
       "      <td>2022-11-02 08:49:04.967000+00:00</td>\n",
       "      <td>1667378431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14957</td>\n",
       "      <td>2022-11-02 08:50:59.720000+00:00</td>\n",
       "      <td>2022-11-02 08:52:53.581000+00:00</td>\n",
       "      <td>1667379059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       started_at                         ended_at  \\\n",
       "0  14955 2022-11-02 08:34:21.469000+00:00 2022-11-02 08:40:14.413000+00:00   \n",
       "1  14956 2022-11-02 08:40:31.774000+00:00 2022-11-02 08:49:04.967000+00:00   \n",
       "2  14957 2022-11-02 08:50:59.720000+00:00 2022-11-02 08:52:53.581000+00:00   \n",
       "\n",
       "        jobId  \n",
       "0  1667378061  \n",
       "1  1667378431  \n",
       "2  1667379059  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 1 \n",
    "# avec les intervalles de temps\n",
    "dataframe1 = jobs_reduced[['started_at', 'ended_at', 'jobId']]\n",
    "# conversion des colonnes au format datetime\n",
    "cols_to_convert = ['started_at', 'ended_at']\n",
    "dataframe1[cols_to_convert] = dataframe1[cols_to_convert].apply(pd.to_datetime)\n",
    "dataframe1 = dataframe1.sort_values('started_at')\n",
    "dataframe1 = dataframe1.reset_index()\n",
    "dataframe1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>jobId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-02 08:28:57.613000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-11-02 08:28:57.675000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-02 08:28:57.675000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        timestamp criticality_events  \\\n",
       "0      2 2022-11-02 08:28:57.613000+00:00              ERROR   \n",
       "1      0 2022-11-02 08:28:57.675000+00:00              ERROR   \n",
       "2      1 2022-11-02 08:28:57.675000+00:00              ERROR   \n",
       "\n",
       "   identification_events  jobId  \n",
       "0                    358      0  \n",
       "1                    358      0  \n",
       "2                    358      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 2 \n",
    "# avec les valeurs de date\n",
    "dataframe2 = pd.DataFrame({\n",
    "    'timestamp': metrics_reduced['timestamp'].values,\n",
    "    'criticality_events': metrics_reduced['criticality_events'].values,\n",
    "    'identification_events': metrics_reduced['identification_events'].values,\n",
    "    'jobId': 0\n",
    "}, index=None)\n",
    "# conversion des colonnes au format datetime\n",
    "dataframe2['timestamp'] = pd.to_datetime(dataframe2['timestamp'])\n",
    "dataframe2 = dataframe2.sort_values('timestamp')\n",
    "dataframe2 = dataframe2.reset_index()\n",
    "dataframe2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ job index 1000 = time 283.4151420593262]\n",
      "[ job index 2000 = time 525.0069441795349]\n",
      "[ job index 3000 = time 746.5483283996582]\n",
      "[ job index 4000 = time 946.5782556533813]\n",
      "[ job index 5000 = time 1109.7836894989014]\n",
      "[ job index 6000 = time 1289.2817380428314]\n",
      "[ job index 7000 = time 1457.198656797409]\n",
      "[ job index 8000 = time 1597.860450744629]\n",
      "[ job index 9000 = time 1731.934752702713]\n",
      "[ job index 10000 = time 1878.5009207725525]\n",
      "[ job index 11000 = time 1998.8242650032043]\n",
      "[ job index 12000 = time 2140.09636759758]\n",
      "[ job index 13000 = time 2324.477144241333]\n",
      "[ job index 14000 = time 2472.2887704372406]\n",
      "[ job index 15000 = time 2648.9095225334167]\n",
      "[ job index 16000 = time 2824.2686533927917]\n",
      "[ job index 17000 = time 2965.6205048561096]\n",
      "[ job index 18000 = time 3108.7507617473602]\n",
      "[ job index 19000 = time 3230.6051230430603]\n",
      "[ job index 20000 = time 3346.863140821457]\n",
      "[ job index 21000 = time 3449.967326402664]\n",
      "[ job index 22000 = time 3552.036420583725]\n",
      "[ job index 23000 = time 3693.7865600585938]\n",
      "[ job index 24000 = time 3893.140557050705]\n",
      "[ job index 25000 = time 4041.610412120819]\n",
      "[ job index 26000 = time 4194.3222551345825]\n",
      "[ job index 27000 = time 4339.021193742752]\n",
      "[ job index 28000 = time 4456.534691333771]\n",
      "[ job index 29000 = time 4606.862685441971]\n",
      "[ job index 30000 = time 4748.703611135483]\n",
      "[ job index 31000 = time 4865.305446147919]\n",
      "[ job index 32000 = time 5054.812140464783]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# début du temps d'execution de la cellule\n",
    "start = time.time()\n",
    "\n",
    "# Parcours chaque ligne de job\n",
    "for index1, row1 in dataframe1.iterrows():\n",
    "    # creation des variables\n",
    "    job_starts = row1.started_at.tz_localize(None)\n",
    "    job_ends = row1.ended_at.tz_localize(None)\n",
    "\n",
    "    # mois de référence\n",
    "    month = job_starts.month\n",
    "    if month != job_ends.month :\n",
    "        dataframe2_by_month = dataframe2[(dataframe2['timestamp'].dt.month == month) | (dataframe2['timestamp'].dt.month == job_ends.month) & (dataframe2['jobId'] == 0)]\n",
    "        dataframe2_by_month = dataframe2_by_month.sort_values('timestamp')\n",
    "    else :\n",
    "        dataframe2_by_month = dataframe2[(dataframe2['timestamp'].dt.month == month) & (dataframe2['jobId'] == 0)]\n",
    "        dataframe2_by_month = dataframe2_by_month.sort_values('timestamp')\n",
    "\n",
    "    for index2, row2 in dataframe2_by_month.iterrows():\n",
    "        # creation des variables\n",
    "        metrics_timestamp = row2['timestamp'].tz_localize(None)\n",
    "        # si le timestamp de la lignes de row2 de metrics est compris dans l'intervalle de temps du job de row1\n",
    "        if metrics_timestamp >= job_starts :\n",
    "            if metrics_timestamp <= job_ends :\n",
    "                dataframe2.loc[index2, 'jobId'] = dataframe1.loc[index1, 'jobId']\n",
    "    # # avant de passer à la row1 suivante\n",
    "    # # on affiche l'index1 toutes les 1000 lignes et son temps d'execution\n",
    "    print(f'[ job index {index1} = time {time.time() - start}]') if index1 % 1000 == 0 and index1 != 0 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO        10004\n",
       "ERROR        7792\n",
       "NO_EVENT     7118\n",
       "WARNING       831\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticality_events pour les lignes du dataframe2 (metrics_df) qui ont été associées à un jobId\n",
    "dataframe2[dataframe2['jobId'] != 0]['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de ligne de metrics : 56955 (dont 25745 avec un jobId associé)\n"
     ]
    }
   ],
   "source": [
    "print(f'Nombre de ligne de metrics : {dataframe2.shape[0]} (dont {dataframe2[dataframe2.jobId != 0].shape[0]} avec un jobId associé)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Fusion des données de job avec les lignes de metrics (dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25745, 55)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = jobs_reduced.merge(dataframe2, on='jobId')\n",
    "merged_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fusion on jobId permet de ne conserver que les lignes de metrics qui ont un jobId."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Equilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de lignes en criticité 'ERROR' : 7792\n"
     ]
    }
   ],
   "source": [
    "# on détermine le nombre de lignes ERROR\n",
    "merge_df_errors = merged_df['criticality_events'][merged_df['criticality_events'] == 'ERROR'].count()\n",
    "print(f\"Le nombre de lignes en criticité 'ERROR' : {merge_df_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réduction des autres classes par rapport à ERROR\n",
    "merged_df = balance_dataframe_by_criticality(merged_df, CRITICALITY_NULL, merge_df_errors)\n",
    "merged_df = balance_dataframe_by_criticality(merged_df, 'WARNING', merge_df_errors)\n",
    "merged_df = balance_dataframe_by_criticality(merged_df, 'INFO', merge_df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO        7792\n",
       "ERROR       7792\n",
       "NO_EVENT    7118\n",
       "WARNING      831\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité pour les lignes du dataframe2 (metrics_df) qui ont été associées à un jobId\n",
    "merged_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(path_or_buf=save_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
