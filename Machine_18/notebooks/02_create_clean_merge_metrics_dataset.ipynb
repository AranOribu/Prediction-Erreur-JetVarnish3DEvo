{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Creation d'un dataset des données nettoyées de metrics (après fractionnement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère :\n",
    "\n",
    "- 1 fichier csv \"merge_clean_metrics_dataset.csv\"\n",
    "\n",
    "Etapes de nettoyage :\n",
    "\n",
    "- Suppression des colonnes n'ayant que des valeurs nulles\n",
    "\n",
    "- Suppression des colonnes avec informations redondantes (identification=message_events) ou inutiles (id de message)\n",
    "\n",
    "- Conversion des types de colonnes avec le type de valeurs\n",
    "\n",
    "- Remplacement des valeurs nulles\n",
    "\n",
    "- Encodage des codes d'identification en chaine de caractères (maj du metrics_events_dict.json) et de la criticité"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to raw metrics dataset\n",
    "source_csv = '../data/metrics/raw_merge_metrics_dataset.csv'\n",
    "# target path to save metrics dictionnaire\n",
    "save_json ='../data/metrics/metrics_events_dict.json'\n",
    "# target path to save merge raw metrics dataset\n",
    "save_csv = '../data/metrics/clean_merge_metrics_dataset.csv'\n",
    "encoded_save_csv = '../data/metrics/encoded_clean_merge_metrics_dataset.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2182421 entries, 0 to 2182420\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   id                         int64  \n",
      " 1   source_events              object \n",
      " 2   message_events             object \n",
      " 3   timestamp_events           object \n",
      " 4   criticality_events         object \n",
      " 5   identification_events      object \n",
      " 6   sn_modules                 float64\n",
      " 7   name_modules               object \n",
      " 8   type_modules               object \n",
      " 9   generation_modules         object \n",
      " 10  name_counters_modules      object \n",
      " 11  value_counters_modules     int64  \n",
      " 12  name_connected_operators   object \n",
      " 13  level_connected_operators  object \n",
      " 14  status                     object \n",
      " 15  created_at                 object \n",
      " 16  varnishLevelsTargetvolume  float64\n",
      " 17  varnishLevelsTotalvolume   int64  \n",
      "dtypes: float64(2), int64(3), object(13)\n",
      "memory usage: 299.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(Path(source_csv), index_col=0)\n",
    "# réindexation à 0\n",
    "df.reset_index(level=None, drop=True, inplace=True, col_level=0, col_fill='')\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Selection des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes ne contenant que des valeurs nulles\n",
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les colonnes doublons (message=identification)\n",
    "df = df.drop(['id', 'message_events'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on converti les float en entier 64\n",
    "df.varnishLevelsTargetvolume = pd.to_numeric(df.varnishLevelsTargetvolume).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2182421 entries, 0 to 2182420\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Dtype \n",
      "---  ------                     ----- \n",
      " 0   source_events              object\n",
      " 1   timestamp_events           object\n",
      " 2   criticality_events         object\n",
      " 3   identification_events      object\n",
      " 4   name_modules               object\n",
      " 5   type_modules               object\n",
      " 6   generation_modules         object\n",
      " 7   name_counters_modules      object\n",
      " 8   value_counters_modules     int64 \n",
      " 9   name_connected_operators   object\n",
      " 10  level_connected_operators  object\n",
      " 11  status                     object\n",
      " 12  created_at                 object\n",
      " 13  varnishLevelsTargetvolume  int64 \n",
      " 14  varnishLevelsTotalvolume   int64 \n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 249.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Colonne 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on renomme la colonne timestamp_events\n",
    "df = df.rename(columns={'timestamp_events':'timestamp'})\n",
    "# on remplace des valeurs maquantes de timestamp par celle de created_at\n",
    "df.timestamp = df.timestamp.fillna(df['created_at'])\n",
    "# on converti les valeur en datetim\n",
    "df.timestamp = pd.to_datetime(df.timestamp, utc=True)\n",
    "# on supprime la colonne doublon (created_at=tiemstamp)\n",
    "df = df.drop(['created_at'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Colonne 'identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['358', '391', nan, '330', '332', '331', '454', '333', '352', '334',\n",
       "       'Kernel_Error', '386', '407', '381', '356',\n",
       "       'iFoil communication error', '479', '329', '344', '440', '406',\n",
       "       '388', '313', '357', '355', '430', '373', '447', '383', '359',\n",
       "       'ICB communication error', '345', '444', '324', '445', '405',\n",
       "       '371', '354', '343', '311', '465', '466', '374', '321', '327',\n",
       "       '322', '382', '350', '325', '451', 'RCB communication error',\n",
       "       '349', '372', '392', '320', '417', '351', '476', '387', '389', '0',\n",
       "       '328', '408', '452', '446', '418'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs nulles par des 0\n",
    "df.identification_events = df.identification_events.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kernel_Error': 1000,\n",
       " 'iFoil communication error': 1001,\n",
       " 'ICB communication error': 1002,\n",
       " 'RCB communication error': 1003}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on encode les valeurs du type 'str' avec un code\n",
    "events_id = []\n",
    "str_code_dict = {}\n",
    "str_code = 1000\n",
    "for id in list(df['identification_events'].unique()) :\n",
    "    try:\n",
    "        events_id.append(int(id))\n",
    "    except ValueError:\n",
    "        str_code_dict[id] = str_code\n",
    "        events_id.append(str_code)\n",
    "        str_code += 1\n",
    "str_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_str_code_dict = {v: k for k, v in str_code_dict.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['identification encoded'] = inv_str_code_dict\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "df.identification_events = df.identification_events.replace(str_code_dict)\n",
    "# on converti toutes les valeurs en entier\n",
    "df.identification_events = pd.to_numeric(df.identification_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 358,  391,    0,  330,  332,  331,  454,  333,  352,  334, 1000,\n",
       "        386,  407,  381,  356, 1001,  479,  329,  344,  440,  406,  388,\n",
       "        313,  357,  355,  430,  373,  447,  383,  359, 1002,  345,  444,\n",
       "        324,  445,  405,  371,  354,  343,  311,  465,  466,  374,  321,\n",
       "        327,  322,  382,  350,  325,  451, 1003,  349,  372,  392,  320,\n",
       "        417,  351,  476,  387,  389,  328,  408,  452,  446,  418],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Encodage des labels 'criticality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "encoded_df.criticality_events = encoded_df.criticality_events.fillna(\"UNDEFINED\")\n",
    "criticality = {'UNDEFINED': 0, 'INFO': 1, 'WARNING': 2, 'ERROR':3}\n",
    "encoded_df.criticality_events.replace(criticality, inplace=True)\n",
    "encoded_df.criticality_events = pd.to_numeric(encoded_df.criticality_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_criticality = {v: k for k, v in criticality.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['criticality encoded'] = inv_criticality\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe avant encodage\n",
    "df.to_csv(path_or_buf=Path(save_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-11-02 08:43:46.921000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>358</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>25411</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>ERR</td>\n",
       "      <td>12766</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-11-02 08:43:46.921000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>358</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>670871</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>ERR</td>\n",
       "      <td>12766</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2022-11-02 08:43:46.845000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>358</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>3359237</td>\n",
       "      <td>User</td>\n",
       "      <td>Operator</td>\n",
       "      <td>ERR</td>\n",
       "      <td>12766</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                        timestamp criticality_events  \\\n",
       "0         iFoil 2022-11-02 08:43:46.921000+00:00               INFO   \n",
       "1         iFoil 2022-11-02 08:43:46.921000+00:00               INFO   \n",
       "2           PLC 2022-11-02 08:43:46.845000+00:00              ERROR   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    358         iFoil L            iFoil             Gen. 2   \n",
       "1                    358         iFoil L            iFoil             Gen. 2   \n",
       "2                    358  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   25411                     User   \n",
       "1  Foiled Pages Counter                  670871                     User   \n",
       "2    3D Varnish Counter                 3359237                     User   \n",
       "\n",
       "  level_connected_operators status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator    ERR                      12766   \n",
       "1                  Operator    ERR                      12766   \n",
       "2                  Operator    ERR                      12766   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                     18000  \n",
       "1                     18000  \n",
       "2                     18000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe après encodage\n",
    "encoded_df.to_csv(path_or_buf=Path(encoded_save_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2315c9af7dedaeb0b2bf51504304a927c605b523f04dad98936c50abe500b408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
