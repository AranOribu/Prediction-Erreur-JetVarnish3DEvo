{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin complet vers le csv servant de source.\n",
    "source_csv = '../data/metrics/raw_merge_metrics_dataset.csv'\n",
    "\n",
    "# Chemin de stockage des csv\n",
    "path = \"../data/metrics/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Import du Dataset originel**<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création Dataframe\n",
    "df = pd.read_csv(source_csv, index_col=0).reset_index(drop=True).dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Préparation du Dataset**<center>\n",
    "\n",
    "### I - Imputation des données manquantes et suppression des colonnes inutiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une liste de colonnes à suppr\n",
    "drop_col = [\"id\", \"message_events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommage de la colonne \"timestamp_events\"\n",
    "if \"timestamp_events\" in df :\n",
    "    df = df.rename(columns={\"timestamp_events\" : \"timestamp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement les données manquants dans la colonne \"timestamp_events\" par les timestamp de la colonne \"created_at\"\n",
    "df.timestamp = df.timestamp.fillna(df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement les données manquants dans la colonne \"timestamp_events\" par les timestamp de la colonne \"created_at\"\n",
    "df.criticality_events = df.criticality_events.fillna(df[\"status\"]).replace(\"ERR\", \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.criticality_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout des colonnes redondante à la liste de colonnes a suppr\n",
    "if \"created_at\" not in drop_col :\n",
    "    drop_col.append(\"created_at\")\n",
    "if \"name_modules\" not in drop_col :\n",
    "    drop_col.append(\"name_modules\")\n",
    "if \"generation_modules\" not in drop_col :\n",
    "    drop_col.append(\"generation_modules\")\n",
    "if \"status\" not in drop_col :\n",
    "    drop_col.append(\"status\")\n",
    "\n",
    "print(drop_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la présence de NaN dans la colonne \"identification_events\"\n",
    "df[\"identification_events\"].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.identification_events = df.identification_events.replace(np.nan, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II - Modification des données textuelles en données numériques et encodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Colonne \"timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation en datetime\n",
    "df.timestamp = pd.to_datetime(df.timestamp, utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Colonne \"identification_events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des 5 id textuelles\n",
    "events_id = []\n",
    "str_code_dict = {}\n",
    "str_code = 500\n",
    "for id in list(df['identification_events'].unique()) :\n",
    "    try:\n",
    "        events_id.append(int(id))\n",
    "    except ValueError:\n",
    "        str_code_dict[id] = str_code\n",
    "        events_id.append(str_code)\n",
    "        str_code += 1\n",
    "str_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs des id textuelles par leur code correspondant\n",
    "df.identification_events = df.identification_events.replace(str_code_dict)\n",
    "# on converti toutes les valeurs en int64\n",
    "df.identification_events = pd.to_numeric(df.identification_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Colonne \"varnishLevelsTargetvolume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on converti les float en entier 64\n",
    "df.varnishLevelsTargetvolume = pd.to_numeric(df.varnishLevelsTargetvolume).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III - Sauvegarde du nouveau dataframe pour réutilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/metrics/Arthur_dataset_V2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "641716e2d83a1b48ea94de6ae288ab2fe5414e63c34b937b40deb4d555d5021e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
