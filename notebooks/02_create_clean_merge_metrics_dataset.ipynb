{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Creation de merge clean metrics dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère :\n",
    "\n",
    "- 1 fichier csv \"merge_clean_metrics_dataset.csv\"\n",
    "\n",
    "Etapes de nettoyage :\n",
    "\n",
    "- Suppression des colonnes n'ayant que des valeurs nulles\n",
    "\n",
    "- Suppression des colonnes avec informations redondantes (identification=message_events) ou inutiles (id de message)\n",
    "\n",
    "- Conversion des types de colonnes avec le type de valeurs\n",
    "\n",
    "- Remplacement des valeurs nulles\n",
    "\n",
    "- Encodage des codes d'identification en chaine de caractères (maj du metrics_events_dict.json) et de la criticité"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to raw metrics dataset\n",
    "source_csv = '../data/metrics/raw_merge_metrics_dataset.csv'\n",
    "# target path to save metrics dictionnaire\n",
    "save_json ='../data/metrics/metrics_events_dict.json'\n",
    "# target path to save merge raw metrics dataset\n",
    "save_csv = '../data/metrics/clean_merge_metrics_dataset.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(Path(source_csv), index_col=0)\n",
    "# réindexation à 0\n",
    "df.reset_index(level=None, drop=True, inplace=True, col_level=0, col_fill='')\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Selection des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes ne contenant que des valeurs nulles\n",
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les colonnes doublons (message=identification)\n",
    "df = df.drop(['id', 'message_events'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on converti les float en entier 64\n",
    "df.varnishLevelsTargetvolume = pd.to_numeric(df.varnishLevelsTargetvolume).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Colonne 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on renomme la colonne timestamp_events\n",
    "df = df.rename(columns={'timestamp_events':'timestamp'})\n",
    "# on remplace des valeurs maquantes de timestamp par celle de created_at\n",
    "df.timestamp = df.timestamp.fillna(df['created_at'])\n",
    "# on converti les valeur en datetim\n",
    "df.timestamp = pd.to_datetime(df.timestamp, utc=True)\n",
    "# on supprime la colonne doublon (created_at=tiemstamp)\n",
    "df = df.drop(['created_at'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Colonne 'identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs nulles par des 0\n",
    "df.identification_events = df.identification_events.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on encode les valeurs du type 'str' avec un code\n",
    "events_id = []\n",
    "str_code_dict = {}\n",
    "str_code = 1000\n",
    "for id in list(df['identification_events'].unique()) :\n",
    "    try:\n",
    "        events_id.append(int(id))\n",
    "    except ValueError:\n",
    "        str_code_dict[id] = str_code\n",
    "        events_id.append(str_code)\n",
    "        str_code += 1\n",
    "str_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_str_code_dict = {v: k for k, v in str_code_dict.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['identification encoded'] = inv_str_code_dict\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "df.identification_events = df.identification_events.replace(str_code_dict)\n",
    "# on converti toutes les valeurs en entier\n",
    "df.identification_events = pd.to_numeric(df.identification_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.identification_events.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Encodage des labels 'criticality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace dans le dataframe les valeurs du type 'str' avec un code\n",
    "df.criticality_events = df.criticality_events.fillna(\"UNDEFINED\")\n",
    "criticality = {'UNDEFINED': 0, 'INFO': 1, 'WARNING': 2, 'ERROR':3}\n",
    "df.criticality_events.replace(criticality, inplace=True)\n",
    "df.criticality_events = pd.to_numeric(df.criticality_events).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sauvegarde l'encodage dans metrics_events_dict\n",
    "inv_criticality = {v: k for k, v in criticality.items()}\n",
    "with open(file=Path(save_json), mode=\"r+\", encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data['criticality encoded'] = inv_criticality\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(data, jsonFile, indent=4, ensure_ascii=False)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du dataframe avant encodage\n",
    "df.to_csv(path_or_buf=Path(save_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2315c9af7dedaeb0b2bf51504304a927c605b523f04dad98936c50abe500b408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
