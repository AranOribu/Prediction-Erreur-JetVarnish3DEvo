{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Création d'un dataset de la fusion des datasets de clean metrics et clean jobs/job_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère 1 csv :\n",
    "\n",
    "- dataset_for_preprocess.csv qui fusionne les données du dataset de metrics et jobs/job_events\n",
    "\n",
    "Etapes : \n",
    "\n",
    "B) Import des datasets : \n",
    "\n",
    "- metrics est quasi-brut (la colonne events est fractionnée et tous les identifiants d'évènements sont des nombres)\n",
    "\n",
    "- jobs (le dataset fusionné des données de jobs et job_events) dont chaque ligne est un job, un job est unique et il a un début et une fin\n",
    "\n",
    "C) Réduction du dataset jobs et réductions succesives du dataset metrics (les lignes évènements avec certains identifiants)\n",
    "\n",
    "D) Concaténation des datasets jobs et metrics (suppression des lignes inutiles : toutes celles de jobs et metrics si aucun jobId associé)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to datasets\n",
    "path = '../data/'\n",
    "metrics = 'metrics/clean_merge_metrics_dataset.csv'\n",
    "jobs = 'jobs/merge_raw_jobs_and_clean_jobevents_dataset.csv'\n",
    "\n",
    "save_csv = '../data/dataset_for_preprocess.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics dataset shape (3510431, 14)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "metrics_df = pd.read_csv(os.path.join(path, metrics), index_col=0)\n",
    "print(f'metrics dataset shape {metrics_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne timestamp contient-elle des valeurs en double ?\n",
    "metrics_df['timestamp'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-04-15 05:55:06.678000+00:00'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242037\n"
     ]
    }
   ],
   "source": [
    "# Grouper les lignes par la colonne \"timestamp\" et obtenir les index correspondants\n",
    "groupes = metrics_df.groupby('timestamp').groups\n",
    "print(len(groupes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-04-15 06:06:56.278000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>22881</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>IDLE</td>\n",
       "      <td>36192</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-04-15 06:06:56.278000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>31092</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>IDLE</td>\n",
       "      <td>36192</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2022-04-15 06:06:56.418000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>330</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>IDLE</td>\n",
       "      <td>36192</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                         timestamp criticality_events  \\\n",
       "0         iFoil  2022-04-15 06:06:56.278000+00:00               INFO   \n",
       "1         iFoil  2022-04-15 06:06:56.278000+00:00               INFO   \n",
       "2           PLC  2022-04-15 06:06:56.418000+00:00               INFO   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    391         iFoil L            iFoil             Gen. 2   \n",
       "1                    391         iFoil L            iFoil             Gen. 2   \n",
       "2                    330  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   22881                   Viktor   \n",
       "1  Foiled Pages Counter                   31092                   Viktor   \n",
       "2    3D Varnish Counter                 1792992                   Viktor   \n",
       "\n",
       "  level_connected_operators status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator   IDLE                      36192   \n",
       "1                  Operator   IDLE                      36192   \n",
       "2                  Operator   IDLE                      36192   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                    100000  \n",
       "1                    100000  \n",
       "2                    100000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs dataset shape (16295, 42)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "jobs_df = pd.read_csv(os.path.join(path, jobs), index_col=0)\n",
    "print(f'jobs dataset shape {jobs_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne started_at contient-elle des valeurs en double ?\n",
    "jobs_df['started_at'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-18 09:22:46.866000+00:00'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df['started_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>paperHeight_job</th>\n",
       "      <th>paperWidth_job</th>\n",
       "      <th>scanner_mode</th>\n",
       "      <th>bars_job</th>\n",
       "      <th>varnishConsumptionVarnish_3d_job</th>\n",
       "      <th>jobId</th>\n",
       "      <th>total_copies_requested</th>\n",
       "      <th>LED</th>\n",
       "      <th>...</th>\n",
       "      <th>leftMargin_remoteScannerRegistration</th>\n",
       "      <th>redScore_gridMode_remoteScannerRegistration</th>\n",
       "      <th>redScore_cropmarksMode_remoteScannerRegistration</th>\n",
       "      <th>redScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>blueScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>greenScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>mode_remoteScannerRegistration</th>\n",
       "      <th>jobState</th>\n",
       "      <th>total_copies</th>\n",
       "      <th>varnishConsumptionVarnish_3d_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-18 09:22:46.866000+00:00</td>\n",
       "      <td>2021-06-18 09:22:46.866000+00:00</td>\n",
       "      <td>520</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624008166</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-18 10:08:13.716000+00:00</td>\n",
       "      <td>2021-06-18 10:10:22.257000+00:00</td>\n",
       "      <td>740</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624010893</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>3</td>\n",
       "      <td>1.440239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-18 10:11:52.165000+00:00</td>\n",
       "      <td>2021-06-18 10:18:20.294000+00:00</td>\n",
       "      <td>740</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624011111</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>CANCELED</td>\n",
       "      <td>70</td>\n",
       "      <td>33.607494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         started_at                          ended_at  \\\n",
       "0  2021-06-18 09:22:46.866000+00:00  2021-06-18 09:22:46.866000+00:00   \n",
       "1  2021-06-18 10:08:13.716000+00:00  2021-06-18 10:10:22.257000+00:00   \n",
       "2  2021-06-18 10:11:52.165000+00:00  2021-06-18 10:18:20.294000+00:00   \n",
       "\n",
       "   paperHeight_job  paperWidth_job  scanner_mode  bars_job  \\\n",
       "0              520             740             0         0   \n",
       "1              740             520             0         0   \n",
       "2              740             520             0         0   \n",
       "\n",
       "   varnishConsumptionVarnish_3d_job       jobId  total_copies_requested  LED  \\\n",
       "0                               0.0  1624008166                       3   10   \n",
       "1                               0.0  1624010893                     100   30   \n",
       "2                               0.0  1624011111                     100   30   \n",
       "\n",
       "   ... leftMargin_remoteScannerRegistration  \\\n",
       "0  ...                                    0   \n",
       "1  ...                                    0   \n",
       "2  ...                                    0   \n",
       "\n",
       "   redScore_gridMode_remoteScannerRegistration  \\\n",
       "0                                         1500   \n",
       "1                                         1500   \n",
       "2                                         1500   \n",
       "\n",
       "   redScore_cropmarksMode_remoteScannerRegistration  \\\n",
       "0                                              1500   \n",
       "1                                              1500   \n",
       "2                                              1500   \n",
       "\n",
       "   redScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                               1500    \n",
       "1                                               1500    \n",
       "2                                               1500    \n",
       "\n",
       "  blueScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 16    \n",
       "1                                                 16    \n",
       "2                                                 16    \n",
       "\n",
       "  greenScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 16     \n",
       "1                                                 10     \n",
       "2                                                 10     \n",
       "\n",
       "   mode_remoteScannerRegistration   jobState  total_copies  \\\n",
       "0                               1  UNDEFINED             0   \n",
       "1                               1      ERROR             3   \n",
       "2                               1   CANCELED            70   \n",
       "\n",
       "  varnishConsumptionVarnish_3d_event  \n",
       "0                           0.000000  \n",
       "1                           1.440239  \n",
       "2                          33.607494  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tailles des datasets sont déséquilibrés :\n",
    "\n",
    "- 3510431 lignes pour metrics\n",
    "\n",
    "- 16295 lignes pour jobs\n",
    "\n",
    "Les dates de début sont différentes :\n",
    "\n",
    "- '2022-04-15 05:55:06.678000+00:00' pour metrics\n",
    "\n",
    "- '2021-06-18 09:22:46.866000+00:00' pour jobs\n",
    "\n",
    "Le dataset metrics compte 1242037 doublons pour la colonne timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Equilibrage des jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Réduction de jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10516, 42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concordance des données de temps dans un même cadre\n",
    "jobs_reduced = jobs_df[jobs_df.started_at > metrics_df.timestamp.min()]\n",
    "jobs_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Réduction de metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par source d'évènement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['iFoil', 'PLC', nan, 'Kernel', 'RCB n°1', 'RCB n°2', 'ICB n°1',\n",
       "       'RCB n°3', 'ICB n°5', 'ICB n°7', 'ICB n°8', 'Pilot', 'ICB n°4',\n",
       "       'ICB n°2', 'ICB n°6'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['source_events'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94166, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on se concentre sur les données de metrics qui ont une source d'évènement\n",
    "metrics_by_source = metrics_df[metrics_df['source_events'].notna()]\n",
    "metrics_by_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO       68501\n",
       "WARNING    12848\n",
       "ERROR      12817\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_by_source['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par identifiant d'évènement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8062, 14)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lignes avec des évènements identifiant une maintenance\n",
    "id_to_drop_1 = [391, 330, 377, 407, 332, 331, 313, 333, 376, 372, 344, 343, 371, 358, 334, 311, 472, 0, 408, 406, 350, 2, 352, 346]\n",
    "# lignes avec des évènements identifiant une intervention humaine\n",
    "id_to_drop_2 = [352, 324, 381, 440, 385, 405, 447, 388, 320, 417, 444, 329, 315, 384, 345, 349, 466, 419]\n",
    "# fusion des listes d'identifiants à supprimer\n",
    "id_to_drop = id_to_drop_1 + id_to_drop_2\n",
    "# on supprime les lignes avec des évènements identifiant une maintenance\n",
    "metrics_by_identification = metrics_by_source[~metrics_by_source['identification_events'].isin(id_to_drop)]\n",
    "metrics_by_identification.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      5933\n",
       "INFO       1530\n",
       "WARNING     599\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_by_identification['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour ne pas avoir un jeu de données trop petit on ne supprime que les 4 premiers idnetifiants les plus représentés mais les moins importants\n",
    "# metrics_by_identification_1 = metrics_by_source[~metrics_by_source['identification_events'].isin([331,330,334,332])]\n",
    "# metrics_by_identification_1['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouper les lignes par la colonne \"timestamp\" et obtenir les index correspondants\n",
    "#len(metrics_by_criticity.groupby('timestamp').groups.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Création du datatset pour le pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reduced = metrics_by_identification.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Comparaison des dates entre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune date commune n'a été trouvée entre les ensembles de données.\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si des dates communes existent\n",
    "dates_communes_exist = jobs_reduced['started_at'].isin(metrics_reduced['timestamp']).any()\n",
    "\n",
    "# Afficher le résultat\n",
    "if dates_communes_exist:\n",
    "    # Filtrer les dates communes\n",
    "    dates_communes = jobs_df['started_at'][jobs_df['started_at'].isin(metrics_df['timestamp'])]\n",
    "    \n",
    "    # Compter le nombre de dates communes\n",
    "    nombre_dates_communes = len(dates_communes)\n",
    "    \n",
    "    print(f\"Des dates communes existent entre les ensembles de données: {nombre_dates_communes}\")\n",
    "else:\n",
    "    print(\"Aucune date commune n'a été trouvée entre les ensembles de données.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de lignes par mois pour chaque dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datetime_series_shapes(s1, s2):\n",
    "    s1_serie = {}\n",
    "    s2_serie = {}\n",
    "    s1 = pd.to_datetime(s1)\n",
    "    s2 = pd.to_datetime(s2)\n",
    "    for i in range(1,13):\n",
    "        s1_month = s1[s1.dt.month == i]\n",
    "        s2_month = s2[s2.dt.month == i]\n",
    "        print(i, s1_month.shape, s2_month.shape)\n",
    "        s1_serie[i] = s1_month.index\n",
    "        s2_serie[i] = s2_month.index\n",
    "    return s1_serie, s2_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0,) (0,)\n",
      "2 (0,) (0,)\n",
      "3 (0,) (0,)\n",
      "4 (728,) (586,)\n",
      "5 (1378,) (1128,)\n",
      "6 (1615,) (1459,)\n",
      "7 (1290,) (1354,)\n",
      "8 (973,) (658,)\n",
      "9 (1276,) (551,)\n",
      "10 (1371,) (814,)\n",
      "11 (1239,) (922,)\n",
      "12 (646,) (590,)\n"
     ]
    }
   ],
   "source": [
    "# on liste les index des lignes par mois\n",
    "jobs_indexes_by_month, metrics_indexes_by_month = compare_datetime_series_shapes(jobs_reduced['started_at'], metrics_reduced['timestamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du nombre de données sur un mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month = 5\n",
    "\n",
    "# Selection des lignes de jobs en Mai\n",
    "# jobs_df['started_at'] = pd.to_datetime(jobs_df['started_at'])\n",
    "# jobs_batch = jobs_df[ (jobs_df['started_at'].dt.month == month)]\n",
    "# jobs_batch = jobs_df.loc[jobs_df.index.isin(jobs_indexes_by_month.get(month))]\n",
    "# jobs_batch.shape\n",
    "\n",
    "# Selection des lignes de metrics en Mai\n",
    "# metrics_df['timestamp'] = pd.to_datetime(metrics_df['timestamp'])\n",
    "# metrics_batch = metrics_df[ (metrics_df['timestamp'].dt.month == month)]\n",
    "# metrics_batch = metrics_df.loc[metrics_df.index.isin(metrics_indexes_by_month.get(month))]\n",
    "# metrics_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Concaténation des datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour chaque ligne de metrics quel est le jobId correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Audrey\\AppData\\Local\\Temp\\ipykernel_9448\\1114395518.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  jobs_reduced['started_at'] = pd.to_datetime(jobs_reduced['started_at'])\n"
     ]
    }
   ],
   "source": [
    "# on prépare la concaténation des données de jobs et metrics du mois de juin\n",
    "\n",
    "month = 0\n",
    "\n",
    "jobs_reduced['started_at'] = pd.to_datetime(jobs_reduced['started_at'])\n",
    "metrics_reduced['timestamp'] = pd.to_datetime(metrics_reduced['timestamp'])\n",
    "\n",
    "if month == 0 :\n",
    "    # DataFrame 1 avec les intervalles de temps\n",
    "    dataframe1 = jobs_reduced.copy()\n",
    "    # DataFrame 2 avec les valeurs de date\n",
    "    dataframe2 = metrics_reduced.copy()\n",
    "else :\n",
    "     # DataFrame 1 avec les intervalles de temps\n",
    "    dataframe1 = jobs_reduced[(jobs_reduced['started_at'].dt.month == month)].copy()\n",
    "    # DataFrame 2 avec les valeurs de date\n",
    "    dataframe2 = metrics_reduced[(metrics_reduced['timestamp'].dt.month == month)].copy()\n",
    "   \n",
    "\n",
    "# Conversion des colonnes en format de date\n",
    "dataframe1['started_at'] = pd.to_datetime(dataframe1['started_at'])\n",
    "dataframe1['ended_at'] = pd.to_datetime(dataframe1['ended_at'])\n",
    "dataframe2['timestamp'] = pd.to_datetime(dataframe2['timestamp'])\n",
    "\n",
    "# Création de la nouvelle colonne dans dataframe2 pour l'association\n",
    "dataframe2['jobId'] = 0\n",
    "\n",
    "# Parcours des lignes de metrics\n",
    "for index2, row2 in dataframe2.iterrows():\n",
    "    metrics_timestamp = row2['timestamp']\n",
    "    # Vérification pour chaque ligne de job\n",
    "    for index1, row1 in dataframe1.iterrows():\n",
    "        if row2['timestamp'] >= row1['started_at'] and row2['timestamp']  <= row1['ended_at']:\n",
    "            dataframe2.loc[index2, 'jobId'] = dataframe1.loc[index1, 'jobId']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      5933\n",
       "INFO       1530\n",
       "WARNING     599\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "dataframe2['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18578, 56)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on concat les données de metrics et jobs\n",
    "concat_df = pd.concat([dataframe1, dataframe2]).reset_index(drop=True)\n",
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      5933\n",
       "INFO       1530\n",
       "WARNING     599\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "concat_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des lignes de metrics sans jobId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12119, 56)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on ne conserve que les lignes qui ont un jobId\n",
    "concat_df = concat_df[concat_df.jobId != 0]\n",
    "concat_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaque ligne de metrics récupère les valeurs du jobId correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs maquantes des lignes metrics par celles de jobs avec le jobId correspondant\n",
    "for job_id in concat_df['jobId'].unique():\n",
    "    if concat_df['jobId'].value_counts().get(job_id, 0) > 1:\n",
    "        concat_df.loc[concat_df['jobId'] == job_id] = concat_df.loc[concat_df['jobId'] == job_id].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      1572\n",
       "INFO         18\n",
       "WARNING      13\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "concat_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des lignes de jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1603, 56)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chaque ligne sans valeur timestamp est une ligne de jobs\n",
    "concat_df_1 = concat_df[~concat_df['timestamp'].isnull()]\n",
    "concat_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      1572\n",
       "INFO         18\n",
       "WARNING      13\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "concat_df_1['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df_1.to_csv(path_or_buf=save_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
