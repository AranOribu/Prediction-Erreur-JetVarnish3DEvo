{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Création d'un dataset de la fusion des datasets de clean metrics et clean jobs/job_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère 1 csv :\n",
    "\n",
    "- dataset_for_preprocess.csv qui fusionne les données du dataset de metrics et jobs/job_events\n",
    "\n",
    "Etapes : \n",
    "\n",
    "B) Import des datasets : \n",
    "\n",
    "- metrics est quasi-brut (la colonne events est fractionnée et tous les identifiants d'évènements sont des nombres)\n",
    "\n",
    "- jobs (le dataset fusionné des données de jobs et job_events) dont chaque ligne est un job, un job est unique et il a un début et une fin\n",
    "\n",
    "C) Réduction du dataset jobs et réductions succesives du dataset metrics (les lignes évènements avec certains identifiants)\n",
    "\n",
    "D) Concaténation des datasets jobs et metrics (suppression des lignes inutiles : toutes celles de jobs et metrics si aucun jobId associé)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to datasets\n",
    "path = '../data/'\n",
    "metrics = 'metrics/clean_merge_metrics_dataset.csv'\n",
    "jobs = 'jobs/merge_raw_jobs_and_clean_jobevents_dataset.csv'\n",
    "\n",
    "save_csv = '../data/dataset_for_preprocess_id_events_filtered_07.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics dataset shape (3510431, 14)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "metrics_df = pd.read_csv(os.path.join(path, metrics), index_col=0)\n",
    "print(f'metrics dataset shape {metrics_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne timestamp contient-elle des valeurs en double ?\n",
    "metrics_df['timestamp'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-04-15 05:55:06.678000+00:00'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242037\n"
     ]
    }
   ],
   "source": [
    "# Grouper les lignes par la colonne \"timestamp\" et obtenir les index correspondants\n",
    "groupes = metrics_df.groupby('timestamp').groups\n",
    "print(len(groupes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_events</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>status</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-04-15 06:06:56.278000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>22881</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>IDLE</td>\n",
       "      <td>36192</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFoil</td>\n",
       "      <td>2022-04-15 06:06:56.278000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>31092</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>IDLE</td>\n",
       "      <td>36192</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLC</td>\n",
       "      <td>2022-04-15 06:06:56.418000+00:00</td>\n",
       "      <td>INFO</td>\n",
       "      <td>330</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>IDLE</td>\n",
       "      <td>36192</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_events                         timestamp criticality_events  \\\n",
       "0         iFoil  2022-04-15 06:06:56.278000+00:00               INFO   \n",
       "1         iFoil  2022-04-15 06:06:56.278000+00:00               INFO   \n",
       "2           PLC  2022-04-15 06:06:56.418000+00:00               INFO   \n",
       "\n",
       "   identification_events    name_modules     type_modules generation_modules  \\\n",
       "0                    391         iFoil L            iFoil             Gen. 2   \n",
       "1                    391         iFoil L            iFoil             Gen. 2   \n",
       "2                    330  Print Engine 1  Varnish Printer                NaN   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0   Total Pages Counter                   22881                   Viktor   \n",
       "1  Foiled Pages Counter                   31092                   Viktor   \n",
       "2    3D Varnish Counter                 1792992                   Viktor   \n",
       "\n",
       "  level_connected_operators status  varnishLevelsTargetvolume  \\\n",
       "0                  Operator   IDLE                      36192   \n",
       "1                  Operator   IDLE                      36192   \n",
       "2                  Operator   IDLE                      36192   \n",
       "\n",
       "   varnishLevelsTotalvolume  \n",
       "0                    100000  \n",
       "1                    100000  \n",
       "2                    100000  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs dataset shape (16295, 42)\n"
     ]
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "jobs_df = pd.read_csv(os.path.join(path, jobs), index_col=0)\n",
    "print(f'jobs dataset shape {jobs_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonne started_at contient-elle des valeurs en double ?\n",
    "jobs_df['started_at'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-18 09:22:46.866000+00:00'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df['started_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>paperHeight_job</th>\n",
       "      <th>paperWidth_job</th>\n",
       "      <th>scanner_mode</th>\n",
       "      <th>bars_job</th>\n",
       "      <th>varnishConsumptionVarnish_3d_job</th>\n",
       "      <th>jobId</th>\n",
       "      <th>total_copies_requested</th>\n",
       "      <th>LED</th>\n",
       "      <th>...</th>\n",
       "      <th>leftMargin_remoteScannerRegistration</th>\n",
       "      <th>redScore_gridMode_remoteScannerRegistration</th>\n",
       "      <th>redScore_cropmarksMode_remoteScannerRegistration</th>\n",
       "      <th>redScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>blueScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>greenScore_fullScannerMode_remoteScannerRegistration</th>\n",
       "      <th>mode_remoteScannerRegistration</th>\n",
       "      <th>jobState</th>\n",
       "      <th>total_copies</th>\n",
       "      <th>varnishConsumptionVarnish_3d_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-18 09:22:46.866000+00:00</td>\n",
       "      <td>2021-06-18 09:22:46.866000+00:00</td>\n",
       "      <td>520</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624008166</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-18 10:08:13.716000+00:00</td>\n",
       "      <td>2021-06-18 10:10:22.257000+00:00</td>\n",
       "      <td>740</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624010893</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>3</td>\n",
       "      <td>1.440239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-18 10:11:52.165000+00:00</td>\n",
       "      <td>2021-06-18 10:18:20.294000+00:00</td>\n",
       "      <td>740</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624011111</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>CANCELED</td>\n",
       "      <td>70</td>\n",
       "      <td>33.607494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         started_at                          ended_at  \\\n",
       "0  2021-06-18 09:22:46.866000+00:00  2021-06-18 09:22:46.866000+00:00   \n",
       "1  2021-06-18 10:08:13.716000+00:00  2021-06-18 10:10:22.257000+00:00   \n",
       "2  2021-06-18 10:11:52.165000+00:00  2021-06-18 10:18:20.294000+00:00   \n",
       "\n",
       "   paperHeight_job  paperWidth_job  scanner_mode  bars_job  \\\n",
       "0              520             740             0         0   \n",
       "1              740             520             0         0   \n",
       "2              740             520             0         0   \n",
       "\n",
       "   varnishConsumptionVarnish_3d_job       jobId  total_copies_requested  LED  \\\n",
       "0                               0.0  1624008166                       3   10   \n",
       "1                               0.0  1624010893                     100   30   \n",
       "2                               0.0  1624011111                     100   30   \n",
       "\n",
       "   ... leftMargin_remoteScannerRegistration  \\\n",
       "0  ...                                    0   \n",
       "1  ...                                    0   \n",
       "2  ...                                    0   \n",
       "\n",
       "   redScore_gridMode_remoteScannerRegistration  \\\n",
       "0                                         1500   \n",
       "1                                         1500   \n",
       "2                                         1500   \n",
       "\n",
       "   redScore_cropmarksMode_remoteScannerRegistration  \\\n",
       "0                                              1500   \n",
       "1                                              1500   \n",
       "2                                              1500   \n",
       "\n",
       "   redScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                               1500    \n",
       "1                                               1500    \n",
       "2                                               1500    \n",
       "\n",
       "  blueScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 16    \n",
       "1                                                 16    \n",
       "2                                                 16    \n",
       "\n",
       "  greenScore_fullScannerMode_remoteScannerRegistration  \\\n",
       "0                                                 16     \n",
       "1                                                 10     \n",
       "2                                                 10     \n",
       "\n",
       "   mode_remoteScannerRegistration   jobState  total_copies  \\\n",
       "0                               1  UNDEFINED             0   \n",
       "1                               1      ERROR             3   \n",
       "2                               1   CANCELED            70   \n",
       "\n",
       "  varnishConsumptionVarnish_3d_event  \n",
       "0                           0.000000  \n",
       "1                           1.440239  \n",
       "2                          33.607494  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tailles des datasets sont déséquilibrés :\n",
    "\n",
    "- 3510431 lignes pour metrics\n",
    "\n",
    "- 16295 lignes pour jobs\n",
    "\n",
    "Les dates de début sont différentes :\n",
    "\n",
    "- '2022-04-15 05:55:06.678000+00:00' pour metrics\n",
    "\n",
    "- '2021-06-18 09:22:46.866000+00:00' pour jobs\n",
    "\n",
    "Le dataset metrics compte 1242037 doublons pour la colonne timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Equilibrage des jeux de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Réduction de jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10516, 42)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concordance des données de temps dans un même cadre\n",
    "jobs_reduced = jobs_df[jobs_df.started_at > metrics_df.timestamp.min()]\n",
    "jobs_reduced.reset_index()\n",
    "jobs_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Réduction de metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par importance d'identifiant d'évènement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3424346, 14)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lignes avec des évènements identifiant une maintenance\n",
    "id_to_drop_1 = [391, 330, 377, 407, 332, 331, 313, 333, 376, 372, 344, 343, 371, 358, 334, 311, 472, 408, 406, 350, 2, 352, 346]\n",
    "# lignes avec des évènements identifiant une intervention humaine\n",
    "id_to_drop_2 = [352, 324, 381, 440, 385, 405, 447, 388, 320, 417, 444, 329, 315, 384, 345, 349, 466, 419]\n",
    "# fusion des listes d'identifiants à supprimer\n",
    "id_to_drop = id_to_drop_1 + id_to_drop_2\n",
    "# on supprime les lignes avec des évènements identifiant une maintenance\n",
    "metrics_by_identification = metrics_df[~metrics_df['identification_events'].isin(id_to_drop)]\n",
    "metrics_by_identification.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3416284\n",
       "454        2845\n",
       "1000       1282\n",
       "355         793\n",
       "386         562\n",
       "356         328\n",
       "357         304\n",
       "1003        294\n",
       "325         287\n",
       "445         240\n",
       "354         195\n",
       "480         160\n",
       "453         155\n",
       "387         154\n",
       "1002        101\n",
       "321          66\n",
       "359          58\n",
       "380          50\n",
       "351          41\n",
       "446          38\n",
       "1001         22\n",
       "323          15\n",
       "479          11\n",
       "430          11\n",
       "460           9\n",
       "411           9\n",
       "471           8\n",
       "475           5\n",
       "416           4\n",
       "389           3\n",
       "476           3\n",
       "1004          2\n",
       "322           2\n",
       "418           2\n",
       "326           2\n",
       "327           1\n",
       "Name: identification_events, dtype: int64"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_by_identification['identification_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par nombre d'identifiant d'évènement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de valeurs d'identification_events pour chaque groupe\n",
    "counts = metrics_by_identification.groupby('identification_events')['identification_events'].transform('count')\n",
    "# Filtrer les lignes où le nombre de valeurs d'identification_events est inférieur à 20\n",
    "metrics_reduced = metrics_by_identification[counts >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3416284\n",
       "454        2845\n",
       "1000       1282\n",
       "355         793\n",
       "386         562\n",
       "356         328\n",
       "357         304\n",
       "1003        294\n",
       "325         287\n",
       "445         240\n",
       "354         195\n",
       "480         160\n",
       "453         155\n",
       "387         154\n",
       "1002        101\n",
       "321          66\n",
       "359          58\n",
       "380          50\n",
       "Name: identification_events, dtype: int64"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par identification_events\n",
    "metrics_reduced['identification_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier équilibrage par identifiant d'évènement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction permettant de reduire le nombre de ligne d'une classe à n lignes\n",
    "def balance_dataframe_by_identification(df, identification, n):\n",
    "    # on filtre les lignes du df qui ont la valeur criticality dans la colonne 'criticality_events'\n",
    "    identification_df = df[df['identification_events'] == identification]\n",
    "    # on selectionne un nombre aléatoire de lignes\n",
    "    identification_df_sample = identification_df.sample(n=n)\n",
    "    # on stoke les index des lignes du df qui ne sont pas dans le sample\n",
    "    index_to_delete = identification_df[~identification_df.index.isin(identification_df_sample.index)].index\n",
    "    # suppression des lignes exclu du sample\n",
    "    return df.drop(index_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454     2845\n",
       "0       2845\n",
       "1000    1282\n",
       "355      793\n",
       "386      562\n",
       "356      328\n",
       "357      304\n",
       "1003     294\n",
       "325      287\n",
       "445      240\n",
       "354      195\n",
       "480      160\n",
       "453      155\n",
       "387      154\n",
       "1002     101\n",
       "321       66\n",
       "359       58\n",
       "380       50\n",
       "Name: identification_events, dtype: int64"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on réduit le nombre de classe pour l'id 0\n",
    "metrics_reduced = balance_dataframe_by_identification(metrics_reduced,0,2845)\n",
    "# on vérifie la distribution par identification_events\n",
    "metrics_reduced['identification_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      5764\n",
       "INFO       1514\n",
       "WARNING     596\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "metrics_reduced['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Création du datatset pour le pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10719, 15)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_reduced['jobId'] = 0\n",
    "metrics_reduced.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Analyse des dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vérifier si des dates communes existent\n",
    "# dates_communes_exist = jobs_reduced['started_at'].isin(metrics_reduced['timestamp']).any()\n",
    "\n",
    "# # Afficher le résultat\n",
    "# if dates_communes_exist:\n",
    "#     # Filtrer les dates communes\n",
    "#     dates_communes = jobs_df['started_at'][jobs_df['started_at'].isin(metrics_df['timestamp'])]\n",
    "    \n",
    "#     # Compter le nombre de dates communes\n",
    "#     nombre_dates_communes = len(dates_communes)\n",
    "    \n",
    "#     print(f\"Des dates communes existent entre les ensembles de données: {nombre_dates_communes}\")\n",
    "# else:\n",
    "#     print(\"Aucune date commune n'a été trouvée entre les ensembles de données.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de dictionnaire du nombre de lignes par mois\n",
    "def compare_datetime_series_shapes(s1, s2):\n",
    "    s1_serie = {}\n",
    "    s2_serie = {}\n",
    "    s1 = pd.to_datetime(s1)\n",
    "    s2 = pd.to_datetime(s2)\n",
    "    for i in range(1,13):\n",
    "        s1_month = s1[s1.dt.month == i]\n",
    "        s2_month = s2[s2.dt.month == i]\n",
    "        print(i, s1_month.shape, s2_month.shape)\n",
    "        s1_serie[i] = s1_month.index\n",
    "        s2_serie[i] = s2_month.index\n",
    "    return s1_serie, s2_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on liste les index des lignes par mois\n",
    "#jobs_indexes_by_month, metrics_indexes_by_month = compare_datetime_series_shapes(jobs_reduced['started_at'], metrics_reduced['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de lignes par mois\n",
    "# month = 5\n",
    "\n",
    "# Selection des lignes de jobs en Mai\n",
    "# jobs_df['started_at'] = pd.to_datetime(jobs_df['started_at'])\n",
    "# jobs_batch = jobs_df[ (jobs_df['started_at'].dt.month == month)]\n",
    "# jobs_batch = jobs_df.loc[jobs_df.index.isin(jobs_indexes_by_month.get(month))]\n",
    "# jobs_batch.shape\n",
    "\n",
    "# Selection des lignes de metrics en Mai\n",
    "# metrics_df['timestamp'] = pd.to_datetime(metrics_df['timestamp'])\n",
    "# metrics_batch = metrics_df[ (metrics_df['timestamp'].dt.month == month)]\n",
    "# metrics_batch = metrics_df.loc[metrics_df.index.isin(metrics_indexes_by_month.get(month))]\n",
    "# metrics_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Correspondance de dates entre metrics et jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour chaque ligne de metrics quel est le jobId correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>jobId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5779</td>\n",
       "      <td>2022-04-15 06:07:27.953000+00:00</td>\n",
       "      <td>2022-04-15 06:10:19.842000+00:00</td>\n",
       "      <td>1650002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5780</td>\n",
       "      <td>2022-04-15 07:02:47.972000+00:00</td>\n",
       "      <td>2022-04-15 07:05:20.268000+00:00</td>\n",
       "      <td>1650006167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5781</td>\n",
       "      <td>2022-04-15 07:07:26.219000+00:00</td>\n",
       "      <td>2022-04-15 07:08:10.478000+00:00</td>\n",
       "      <td>1650006446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       started_at                         ended_at  \\\n",
       "0   5779 2022-04-15 06:07:27.953000+00:00 2022-04-15 06:10:19.842000+00:00   \n",
       "1   5780 2022-04-15 07:02:47.972000+00:00 2022-04-15 07:05:20.268000+00:00   \n",
       "2   5781 2022-04-15 07:07:26.219000+00:00 2022-04-15 07:08:10.478000+00:00   \n",
       "\n",
       "        jobId  \n",
       "0  1650002847  \n",
       "1  1650006167  \n",
       "2  1650006446  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 1 \n",
    "# avec les intervalles de temps\n",
    "dataframe1 = jobs_reduced[['started_at', 'ended_at', 'jobId']]\n",
    "# conversion des colonnes au format datetime\n",
    "cols_to_convert = ['started_at', 'ended_at']\n",
    "dataframe1[cols_to_convert] = dataframe1[cols_to_convert].apply(pd.to_datetime)\n",
    "dataframe1 = dataframe1.sort_values('started_at')\n",
    "dataframe1 = dataframe1.reset_index()\n",
    "dataframe1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>jobId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4268</td>\n",
       "      <td>2022-04-15 05:58:14.754000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4269</td>\n",
       "      <td>2022-04-15 06:10:23.565000+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4270</td>\n",
       "      <td>2022-04-15 06:20:57.022000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        timestamp criticality_events  \\\n",
       "0   4268 2022-04-15 05:58:14.754000+00:00                NaN   \n",
       "1   4269 2022-04-15 06:10:23.565000+00:00              ERROR   \n",
       "2   4270 2022-04-15 06:20:57.022000+00:00                NaN   \n",
       "\n",
       "   identification_events  jobId  \n",
       "0                      0      0  \n",
       "1                   1000      0  \n",
       "2                      0      0  "
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 2 \n",
    "# avec les valeurs de date\n",
    "dataframe2 = pd.DataFrame({\n",
    "    'timestamp': metrics_reduced['timestamp'].values,\n",
    "    'criticality_events': metrics_reduced['criticality_events'].values,\n",
    "    'identification_events': metrics_reduced['identification_events'].values,\n",
    "    'jobId': 0\n",
    "}, index=None)\n",
    "# conversion des colonnes au format datetime\n",
    "dataframe2['timestamp'] = pd.to_datetime(dataframe2['timestamp'])\n",
    "dataframe2 = dataframe2.sort_values('timestamp')\n",
    "dataframe2 = dataframe2.reset_index()\n",
    "dataframe2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ job index 1000 = time 16.661453008651733]\n",
      "[ job index 2000 = time 40.68084526062012]\n",
      "[ job index 3000 = time 69.38685989379883]\n",
      "[ job index 4000 = time 96.23442459106445]\n",
      "[ job index 5000 = time 121.95805358886719]\n",
      "[ job index 6000 = time 136.78272414207458]\n",
      "[ job index 7000 = time 149.66488313674927]\n",
      "[ job index 8000 = time 166.97123003005981]\n",
      "[ job index 9000 = time 185.33247828483582]\n",
      "[ job index 10000 = time 203.78303408622742]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# début du temps d'execution de la cellule\n",
    "start = time.time()\n",
    "\n",
    "# Parcours chaque ligne de job\n",
    "for index1, row1 in dataframe1.iterrows():\n",
    "    # creation des variables\n",
    "    job_starts = row1.started_at.tz_localize(None)\n",
    "    job_ends = row1.ended_at.tz_localize(None)\n",
    "\n",
    "    # mois de référence\n",
    "    month = job_starts.month\n",
    "    if month != job_ends.month :\n",
    "        dataframe2_by_month = dataframe2[(dataframe2['timestamp'].dt.month == month) | (dataframe2['timestamp'].dt.month == job_ends.month) & (dataframe2['jobId'] == 0)]\n",
    "        dataframe2_by_month = dataframe2_by_month.sort_values('timestamp')\n",
    "    else :\n",
    "        dataframe2_by_month = dataframe2[(dataframe2['timestamp'].dt.month == month) & (dataframe2['jobId'] == 0)]\n",
    "        dataframe2_by_month = dataframe2_by_month.sort_values('timestamp')\n",
    "\n",
    "    for index2, row2 in dataframe2_by_month.iterrows():\n",
    "        # creation des variables\n",
    "        metrics_timestamp = row2['timestamp'].tz_localize(None)\n",
    "        # si le timestamp de la lignes de row2 de metrics est compris dans l'intervalle de temps du job de row1\n",
    "        if metrics_timestamp >= job_starts :\n",
    "            if metrics_timestamp <= job_ends :\n",
    "                dataframe2.loc[index2, 'jobId'] = dataframe1.loc[index1, 'jobId']\n",
    "    # # avant de passer à la row1 suivante\n",
    "    # # on affiche l'index1 toutes les 1000 lignes et son temps d'execution\n",
    "    print(f'[ job index {index1} = time {time.time() - start}]') if index1 % 1000 == 0 and index1 != 0 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       988\n",
       "454     668\n",
       "325     228\n",
       "355     166\n",
       "357      83\n",
       "356      69\n",
       "387      68\n",
       "445      50\n",
       "354      50\n",
       "453      42\n",
       "1003     41\n",
       "359      26\n",
       "386      25\n",
       "1002     19\n",
       "480      12\n",
       "1000      5\n",
       "321       3\n",
       "Name: identification_events, dtype: int64"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par identification_events pour les lignes du dataframe2 (metrics_df) qui ont été associées à un jobId\n",
    "dataframe2[dataframe2['jobId'] != 0]['identification_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de ligne de metrics : 10719 (dont 2543 avec un jobId associé)\n"
     ]
    }
   ],
   "source": [
    "print(f'Nombre de ligne de metrics : {dataframe2.shape[0]} (dont {dataframe2[dataframe2.jobId != 0].shape[0]} avec un jobId associé)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Fusion des dataframes jobs et metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2543, 46)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = jobs_reduced.merge(dataframe2, on='jobId')\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       988\n",
       "454     668\n",
       "325     228\n",
       "355     166\n",
       "357      83\n",
       "356      69\n",
       "387      68\n",
       "445      50\n",
       "354      50\n",
       "453      42\n",
       "1003     41\n",
       "359      26\n",
       "386      25\n",
       "1002     19\n",
       "480      12\n",
       "1000      5\n",
       "321       3\n",
       "Name: identification_events, dtype: int64"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "merged_df['identification_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR      1529\n",
       "INFO         14\n",
       "WARNING      12\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "merged_df['criticality_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe ne contenant que des criticality = ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_error = merged_df[merged_df.criticality_events == 'ERROR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454     668\n",
       "325     228\n",
       "355     148\n",
       "357      77\n",
       "387      68\n",
       "356      67\n",
       "445      50\n",
       "354      50\n",
       "453      42\n",
       "1003     41\n",
       "359      26\n",
       "386      25\n",
       "1002     19\n",
       "480      12\n",
       "1000      5\n",
       "321       3\n",
       "Name: identification_events, dtype: int64"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie la distribution par criticité\n",
    "merged_df_error['identification_events'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equilibrage des classes identification_events en fonction de l'id le plus fréquent des lignes ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'id '454' est le plus fréquent des lignes ERROR avec 668 lignes.\n"
     ]
    }
   ],
   "source": [
    "# on identifie la classe identification_events la plus fréquente dans les ERROR\n",
    "identification_counts = merged_df[merged_df['criticality_events'] == 'ERROR']['identification_events'].value_counts()\n",
    "most_frequent_identification_event = identification_counts.idxmax()\n",
    "nombre_lignes = identification_counts[most_frequent_identification_event]\n",
    "print(f\"L'id '{most_frequent_identification_event}' est le plus fréquent des lignes ERROR avec {nombre_lignes} lignes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO balance_dataframe_by_identification\n",
    "# itérer dans le dataframe pour soit \n",
    "# réduire les classes trop représentées\n",
    "# soit augmenter les moins représentées \n",
    "# par rapport à un seuil n\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(path_or_buf=save_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
