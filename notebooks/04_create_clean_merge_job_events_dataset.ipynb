{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de exploration des données jobs_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook génère 1 csv :\n",
    "\n",
    "- clean_merge_job_events_dataset.csv\n",
    "\n",
    "Etapes :\n",
    "\n",
    "- Suppression des lignes avec les valeurs timestamp_start manquantes\n",
    "\n",
    "- Suppression des colonnes ayant des valeurs uniques\n",
    "\n",
    "- Remplacement des données maquantes\n",
    "\n",
    "- Conversion des types des séries en fonction des types des valeurs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source path to raw metrics dataset\n",
    "filename = 'raw_merge_job_events_dataset.csv'\n",
    "path = '../data/jobs'\n",
    "job_events = os.path.join(path, filename)\n",
    "# target path to save merge raw metrics dataset\n",
    "save_csv = '../data/jobs/clean_merge_job_events_dataset.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Création"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(job_events, index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réindexation\n",
    "df.reset_index(level=None, drop=True, inplace=True, col_level=0, col_fill='')\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Suppression de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on cherche les index des lignes sans timestamp de départ\n",
    "no_start_row = list(df[df['timestamp_start'].isna()].index)\n",
    "no_start_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les lignes sans timestamp de départ\n",
    "df.drop(no_start_row, axis=0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Suppression de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des colonnes\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des types des colonnes\n",
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes non pertinentes\n",
    "col_to_drop = [\n",
    "    'path', \n",
    "    'image']\n",
    "df.drop(col_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Données maquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on liste les colonnes qui contiennent des valeurs nulles\n",
    "col_with_nan = []\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        col_with_nan.append(col)\n",
    "        print(f'{col} : {df[col].unique()}') if df[col].nunique() <= 10 else print(f'{col} : {df[col].nunique()} - dtype : {df[col].dtype}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les 'name_paperFormat' sans nom par UNDEFINED\n",
    "df['name_paperFormat_layout'] = df['name_paperFormat_layout'].fillna('UNDEFINED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les 'jobState' non défini par UNDEFINED\n",
    "df['jobState'] = df['jobState'].fillna('UNDEFINED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on converti les valeur de 'timestamp_end' en booléen\n",
    "#df['timestamp_end'] = df['timestamp_end'].apply(lambda x: False if pd.isna(x) else True)\n",
    "df['timestamp_end'] = df['timestamp_end'].fillna(df['timestamp_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs de 'totalCopies_end' nulles par 0\n",
    "df['totalCopies_end'] = df['totalCopies_end'].fillna(float(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs de 'varnishConsumption' nulles par 0\n",
    "df['consumption_operatorSideTanks_varnishConsumption'] = df['consumption_operatorSideTanks_varnishConsumption'].fillna(float(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conversion de type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion des colonnes de type 'float' dont toutes les valeurs ont des décimales à 0 en type 'int'\n",
    "for col in list(df.select_dtypes(exclude=['object','bool']).columns):\n",
    "    if not True in (math.modf(value)[0] != float(0) for value in list(df[col].unique())):\n",
    "        df[col] = df[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on liste les valeurs (si pas plus de 5) des colonnes de type object\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    print(f\"{col} : {df[col].unique()}\") if df[col].nunique() <= 5  else print(f\"{col} : {df[col].nunique()} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut convertir certaines colonnes au format datetime\n",
    "df['timestamp_start'] = pd.to_datetime(df['timestamp_start'], utc=True)\n",
    "df['timestamp_end'] = pd.to_datetime(df['timestamp_end'], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut convertir le type des colonnes contenant True au format booléen\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    values = list(df[col].unique())\n",
    "    if True in (len(values) == 2  and value == True for value in values):\n",
    "        df[col] = df[col].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on liste les valeurs (si pas plus de 5) des colonnes de type object\n",
    "for col in list(df.select_dtypes(include=['object']).columns):\n",
    "    print(f\"{col} : {df[col].unique()}\") if df[col].nunique() <= 5  else print(f\"{col} : {df[col].nunique()} values\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf=Path(save_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2315c9af7dedaeb0b2bf51504304a927c605b523f04dad98936c50abe500b408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
