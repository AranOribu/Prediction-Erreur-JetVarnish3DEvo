{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler , OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import ColSpec, TensorSpec\n",
    "from mlflow.types import Schema\n",
    "\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.regularizers import L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALLAN\\AppData\\Local\\Temp\\ipykernel_41240\\1742999737.py:5: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sn_modules</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>source_events</th>\n",
       "      <th>message_events</th>\n",
       "      <th>timestamp_events</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>created_at</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4169748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-15 05:55:06.678000</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4169748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>22881</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-15 05:55:06.678000</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sn_modules    name_modules     type_modules generation_modules  \\\n",
       "0  4169748         NaN  Print Engine 1  Varnish Printer                NaN   \n",
       "1  4169748         NaN         iFoil L            iFoil             Gen. 2   \n",
       "\n",
       "  name_counters_modules  value_counters_modules name_connected_operators  \\\n",
       "0    3D Varnish Counter                 1792992                   Viktor   \n",
       "1   Total Pages Counter                   22881                   Viktor   \n",
       "\n",
       "  level_connected_operators source_events message_events timestamp_events  \\\n",
       "0                  Operator           NaN            NaN              NaN   \n",
       "1                  Operator           NaN            NaN              NaN   \n",
       "\n",
       "  criticality_events identification_events                  created_at  \\\n",
       "0                NaN                   NaN  2022-04-15 05:55:06.678000   \n",
       "1                NaN                   NaN  2022-04-15 05:55:06.678000   \n",
       "\n",
       "   varnishLevelsTargetvolume  varnishLevelsTotalvolume  \n",
       "0               36192.322612                    100000  \n",
       "1               36192.322612                    100000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nom de fichier et chemin relatif\n",
    "filename = 'merge_raw_metrics_dataset.csv'\n",
    "path = '../../data/metrics/'\n",
    "# création d'un dataframe à partir du csv de données\n",
    "df = pd.read_csv(\n",
    "    path+filename, index_col=0).sort_values(by='created_at', ascending=True)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sn_modules</th>\n",
       "      <th>name_modules</th>\n",
       "      <th>type_modules</th>\n",
       "      <th>generation_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>name_connected_operators</th>\n",
       "      <th>level_connected_operators</th>\n",
       "      <th>source_events</th>\n",
       "      <th>message_events</th>\n",
       "      <th>timestamp_events</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.678</th>\n",
       "      <td>4169748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.678</th>\n",
       "      <td>4169748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>22881</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.678</th>\n",
       "      <td>4169748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>31092</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.829</th>\n",
       "      <td>4169749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>Varnish Printer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>PLC</td>\n",
       "      <td>JV-Ti non prêt : impression impossible</td>\n",
       "      <td>2022-04-15T05:55:23.462Z</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.829</th>\n",
       "      <td>4169749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iFoil L</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>Gen. 2</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>22881</td>\n",
       "      <td>Viktor</td>\n",
       "      <td>Operator</td>\n",
       "      <td>PLC</td>\n",
       "      <td>JV-Ti non prêt : impression impossible</td>\n",
       "      <td>2022-04-15T05:55:23.462Z</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  sn_modules    name_modules     type_modules  \\\n",
       "created_at                                                                      \n",
       "2022-04-15 05:55:06.678  4169748         NaN  Print Engine 1  Varnish Printer   \n",
       "2022-04-15 05:55:06.678  4169748         NaN         iFoil L            iFoil   \n",
       "2022-04-15 05:55:06.678  4169748         NaN         iFoil L            iFoil   \n",
       "2022-04-15 05:55:06.829  4169749         NaN  Print Engine 1  Varnish Printer   \n",
       "2022-04-15 05:55:06.829  4169749         NaN         iFoil L            iFoil   \n",
       "\n",
       "                        generation_modules name_counters_modules  \\\n",
       "created_at                                                         \n",
       "2022-04-15 05:55:06.678                NaN    3D Varnish Counter   \n",
       "2022-04-15 05:55:06.678             Gen. 2   Total Pages Counter   \n",
       "2022-04-15 05:55:06.678             Gen. 2  Foiled Pages Counter   \n",
       "2022-04-15 05:55:06.829                NaN    3D Varnish Counter   \n",
       "2022-04-15 05:55:06.829             Gen. 2   Total Pages Counter   \n",
       "\n",
       "                         value_counters_modules name_connected_operators  \\\n",
       "created_at                                                                 \n",
       "2022-04-15 05:55:06.678                 1792992                   Viktor   \n",
       "2022-04-15 05:55:06.678                   22881                   Viktor   \n",
       "2022-04-15 05:55:06.678                   31092                   Viktor   \n",
       "2022-04-15 05:55:06.829                 1792992                   Viktor   \n",
       "2022-04-15 05:55:06.829                   22881                   Viktor   \n",
       "\n",
       "                        level_connected_operators source_events  \\\n",
       "created_at                                                        \n",
       "2022-04-15 05:55:06.678                  Operator           NaN   \n",
       "2022-04-15 05:55:06.678                  Operator           NaN   \n",
       "2022-04-15 05:55:06.678                  Operator           NaN   \n",
       "2022-04-15 05:55:06.829                  Operator           PLC   \n",
       "2022-04-15 05:55:06.829                  Operator           PLC   \n",
       "\n",
       "                                                  message_events  \\\n",
       "created_at                                                         \n",
       "2022-04-15 05:55:06.678                                      NaN   \n",
       "2022-04-15 05:55:06.678                                      NaN   \n",
       "2022-04-15 05:55:06.678                                      NaN   \n",
       "2022-04-15 05:55:06.829   JV-Ti non prêt : impression impossible   \n",
       "2022-04-15 05:55:06.829   JV-Ti non prêt : impression impossible   \n",
       "\n",
       "                                 timestamp_events criticality_events  \\\n",
       "created_at                                                             \n",
       "2022-04-15 05:55:06.678                       NaN                NaN   \n",
       "2022-04-15 05:55:06.678                       NaN                NaN   \n",
       "2022-04-15 05:55:06.678                       NaN                NaN   \n",
       "2022-04-15 05:55:06.829  2022-04-15T05:55:23.462Z               INFO   \n",
       "2022-04-15 05:55:06.829  2022-04-15T05:55:23.462Z               INFO   \n",
       "\n",
       "                        identification_events  varnishLevelsTargetvolume  \\\n",
       "created_at                                                                 \n",
       "2022-04-15 05:55:06.678                   NaN               36192.322612   \n",
       "2022-04-15 05:55:06.678                   NaN               36192.322612   \n",
       "2022-04-15 05:55:06.678                   NaN               36192.322612   \n",
       "2022-04-15 05:55:06.829                   391               36192.322612   \n",
       "2022-04-15 05:55:06.829                   391               36192.322612   \n",
       "\n",
       "                         varnishLevelsTotalvolume  \n",
       "created_at                                         \n",
       "2022-04-15 05:55:06.678                    100000  \n",
       "2022-04-15 05:55:06.678                    100000  \n",
       "2022-04-15 05:55:06.678                    100000  \n",
       "2022-04-15 05:55:06.829                    100000  \n",
       "2022-04-15 05:55:06.829                    100000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "df = df.sort_values(by='created_at')\n",
    "df.set_index('created_at', inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sn_modules', 'name_modules', 'type_modules',\n",
       "       'generation_modules', 'name_counters_modules', 'value_counters_modules',\n",
       "       'name_connected_operators', 'level_connected_operators',\n",
       "       'source_events', 'message_events', 'timestamp_events',\n",
       "       'criticality_events', 'identification_events',\n",
       "       'varnishLevelsTargetvolume', 'varnishLevelsTotalvolume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3546276, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "sn_modules               True\n",
      "generation_modules       True\n",
      "source_events            True\n",
      "message_events           True\n",
      "timestamp_events         True\n",
      "criticality_events       True\n",
      "identification_events    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "null_columns = df.isna().any()\n",
    "print(\"Columns with missing values:\")\n",
    "print(null_columns[null_columns == True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3546276, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cela va supprimer la colonne sn car vide\n",
    "df.dropna(axis='columns', how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['varnishLevelsTotalvolume'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['generation_modules'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime les colonnes :\n",
    "# message events car redondante avec la colonne identification_events \n",
    "# id , name_connected_operators, level_connected_operators car inutiles pour entrainer le model\n",
    "# timestamp_events : on a déjà une date pour l'index qui servi pour les prediction dans le temps\n",
    "# A VERIFIER : generation_modules , la colonne dispose d'une seul valeur qui est 'gen2' \n",
    "# 'name_modules' information redondante avec 'type_modules'\n",
    "df.drop(columns=['message_events','type_modules','id','name_connected_operators','level_connected_operators','generation_modules','timestamp_events'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3546276, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '391', '330', '332', '377', '333', '334', '331',\n",
       "       'Kernel_Error', '315', '417', '406', '407', '352', '344',\n",
       "       'ICB communication error', '376', '445', '325', '343', '345',\n",
       "       '358', '453', '381', '354', '313', '447', '454', '387', '386',\n",
       "       '372', '371', '323', '480', '311', '479', '351', '440', '324',\n",
       "       '321', '0', '349', 'RCB communication error', '385', '357', '418',\n",
       "       '446', '355', '389', '476', '356', 'iFoil communication error',\n",
       "       '460', '472', '405', '380', '388', '408', 445.0, 391.0, 330.0,\n",
       "       333.0, 408.0, 407.0, 406.0, 332.0, 334.0, 472.0, 331.0, 352.0,\n",
       "       '320', '329', '350', '475', '466', '416', '411', '346', '471',\n",
       "       '327', 430.0, '430', '444', '2', '326', '419',\n",
       "       'Pilot communication error', '359', 313.0, 377.0, 453.0, 376.0,\n",
       "       344.0, 325.0, 454.0, 315.0, 417.0, '322', 385.0, 371.0, 386.0,\n",
       "       '384'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['identification_events'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the mapping for non-integer strings\n",
    "non_int_string_mapping = {}\n",
    "next_mapping_value = 1000\n",
    "# 'Kernel_Error' = 1000 , 'ICB communication error' = 1001 ; 'RCB communication error' = 1002 , 'iFoil communication error' = 1003 , 'Pilot communication error' = \n",
    "\n",
    "# Function to convert the value\n",
    "def convert_value(value):\n",
    "    global next_mapping_value\n",
    "\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "\n",
    "    if isinstance(value, (int, float)):\n",
    "        return int(value)\n",
    "    \n",
    "    if value.isdigit():\n",
    "        return int(value)\n",
    "    \n",
    "    if value not in non_int_string_mapping:\n",
    "        non_int_string_mapping[value] = next_mapping_value\n",
    "        next_mapping_value += 1\n",
    "        \n",
    "    return non_int_string_mapping[value]\n",
    "\n",
    "# Apply the conversion function to the 'identification_events' column\n",
    "df['identification_events'] = df['identification_events'].apply(convert_value)\n",
    "\n",
    "# Convert the column to integers, keeping NaN values as float\n",
    "df['identification_events'] = df['identification_events'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[<NA>,  391,  330,  332,  377,  333,  334,  331, 1000,  315,  417,  406,  407,\n",
       "  352,  344, 1001,  376,  445,  325,  343,  345,  358,  453,  381,  354,  313,\n",
       "  447,  454,  387,  386,  372,  371,  323,  480,  311,  479,  351,  440,  324,\n",
       "  321,    0,  349, 1002,  385,  357,  418,  446,  355,  389,  476,  356, 1003,\n",
       "  460,  472,  405,  380,  388,  408,  320,  329,  350,  475,  466,  416,  411,\n",
       "  346,  471,  327,  430,  444,    2,  326,  419, 1004,  359,  322,  384]\n",
       "Length: 77, dtype: Int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['identification_events'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'PLC', 'iFoil', 'Kernel', 'ICB n°5', 'RCB n°1', 'RCB n°2',\n",
       "       'RCB n°3', 'ICB n°7', 'ICB n°4', 'ICB n°8', 'ICB n°2', 'ICB n°1',\n",
       "       'ICB n°6', 'Pilot'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source_events'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_events: 3302193 valeurs manquantes sur 3546276\n",
      "criticality_events: 3302193 valeurs manquantes sur 3546276\n",
      "identification_events: 3302193 valeurs manquantes sur 3546276\n"
     ]
    }
   ],
   "source": [
    "# count null values in each column\n",
    "null_values_count = df.isnull().sum()\n",
    "\n",
    "for column, value in null_values_count.items():\n",
    "    if value > 0:\n",
    "        print(f\"{column}: {value} valeurs manquantes sur {df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFO       179610\n",
       "WARNING     34497\n",
       "ERROR       29976\n",
       "Name: criticality_events, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['criticality_events'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name_modules', 'name_counters_modules', 'source_events']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify categorical columns (excluding the target column 'criticality')\n",
    "categorical_columns = ['name_modules',  'name_counters_modules', 'source_events']\n",
    "\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with 'nan' in 'criticality_events'\n",
    "df.dropna(subset=['criticality_events'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-04-15 05:55:06.829000', '2022-04-15 05:55:06.829000',\n",
       "               '2022-04-15 05:55:06.829000', '2022-04-15 06:06:35.404000',\n",
       "               '2022-04-15 06:06:35.404000', '2022-04-15 06:06:35.404000',\n",
       "               '2022-04-15 06:06:35.404000', '2022-04-15 06:06:35.404000',\n",
       "               '2022-04-15 06:06:35.404000', '2022-04-15 06:07:05.443000',\n",
       "               ...\n",
       "               '2022-12-12 08:19:07.632000', '2022-12-12 08:19:48.688000',\n",
       "               '2022-12-12 08:19:48.688000', '2022-12-12 08:19:48.688000',\n",
       "               '2022-12-12 08:20:17.777000', '2022-12-12 08:20:17.777000',\n",
       "               '2022-12-12 08:20:17.777000', '2022-12-12 08:21:18.076000',\n",
       "               '2022-12-12 08:21:18.076000', '2022-12-12 08:21:18.076000'],\n",
       "              dtype='datetime64[ns]', name='created_at', length=244083, freq=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select the last row from `X_test` (before encoding) for an MLFLOW input example\n",
    "last_row_enxample = df.iloc[-1]\n",
    "\n",
    "# 2. Create a JSON object using the original row and column names\n",
    "example_input_json = last_row_enxample.to_dict()\n",
    "\n",
    "# Save the JSON object to a file\n",
    "import json\n",
    "with open(\"example_input.json\", \"w\") as f:\n",
    "    json.dump(example_input_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_modules</th>\n",
       "      <th>name_counters_modules</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>source_events</th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.829</th>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>PLC</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.829</th>\n",
       "      <td>iFoil L</td>\n",
       "      <td>Total Pages Counter</td>\n",
       "      <td>22881</td>\n",
       "      <td>PLC</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 05:55:06.829</th>\n",
       "      <td>iFoil L</td>\n",
       "      <td>Foiled Pages Counter</td>\n",
       "      <td>31092</td>\n",
       "      <td>PLC</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 06:06:35.404</th>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>iFoil</td>\n",
       "      <td>INFO</td>\n",
       "      <td>391</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-15 06:06:35.404</th>\n",
       "      <td>Print Engine 1</td>\n",
       "      <td>3D Varnish Counter</td>\n",
       "      <td>1792992</td>\n",
       "      <td>PLC</td>\n",
       "      <td>INFO</td>\n",
       "      <td>330</td>\n",
       "      <td>36192.322612</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name_modules name_counters_modules  \\\n",
       "created_at                                                      \n",
       "2022-04-15 05:55:06.829  Print Engine 1    3D Varnish Counter   \n",
       "2022-04-15 05:55:06.829         iFoil L   Total Pages Counter   \n",
       "2022-04-15 05:55:06.829         iFoil L  Foiled Pages Counter   \n",
       "2022-04-15 06:06:35.404  Print Engine 1    3D Varnish Counter   \n",
       "2022-04-15 06:06:35.404  Print Engine 1    3D Varnish Counter   \n",
       "\n",
       "                         value_counters_modules source_events  \\\n",
       "created_at                                                      \n",
       "2022-04-15 05:55:06.829                 1792992           PLC   \n",
       "2022-04-15 05:55:06.829                   22881           PLC   \n",
       "2022-04-15 05:55:06.829                   31092           PLC   \n",
       "2022-04-15 06:06:35.404                 1792992         iFoil   \n",
       "2022-04-15 06:06:35.404                 1792992           PLC   \n",
       "\n",
       "                        criticality_events  identification_events  \\\n",
       "created_at                                                          \n",
       "2022-04-15 05:55:06.829               INFO                    391   \n",
       "2022-04-15 05:55:06.829               INFO                    391   \n",
       "2022-04-15 05:55:06.829               INFO                    391   \n",
       "2022-04-15 06:06:35.404               INFO                    391   \n",
       "2022-04-15 06:06:35.404               INFO                    330   \n",
       "\n",
       "                         varnishLevelsTargetvolume  varnishLevelsTotalvolume  \n",
       "created_at                                                                    \n",
       "2022-04-15 05:55:06.829               36192.322612                    100000  \n",
       "2022-04-15 05:55:06.829               36192.322612                    100000  \n",
       "2022-04-15 05:55:06.829               36192.322612                    100000  \n",
       "2022-04-15 06:06:35.404               36192.322612                    100000  \n",
       "2022-04-15 06:06:35.404               36192.322612                    100000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\HubAcademy\\AI\\MGI\\Prediction-Erreur-JetVarnish3D\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns except for 'criticality_events'\n",
    "cat_columns = ['name_modules', 'name_counters_modules', 'source_events']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "cat_data_encoded = ohe.fit_transform(df[cat_columns])\n",
    "\n",
    "# Convert the encoded data to a DataFrame\n",
    "cat_data_encoded_df = pd.DataFrame(cat_data_encoded, columns=ohe.get_feature_names_out(cat_columns))\n",
    "\n",
    "# Drop the original categorical columns from the DataFrame\n",
    "df_encoded = df.drop(cat_columns, axis=1)\n",
    "\n",
    "# Reset the index of both DataFrames to avoid index-related issues\n",
    "df_encoded.reset_index(drop=True, inplace=True)\n",
    "cat_data_encoded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "df_encoded = pd.concat([df_encoded, cat_data_encoded_df], axis=1)\n",
    "\n",
    "# Label encode 'criticality_events' column\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.array(['INFO', 'WARNING', 'ERROR'])\n",
    "df_encoded['criticality_events'] = le.fit_transform(df_encoded['criticality_events'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical columns\n",
    "numerical_columns = ['value_counters_modules', 'identification_events', 'varnishLevelsTargetvolume', 'varnishLevelsTotalvolume']\n",
    "scaler = MinMaxScaler()\n",
    "df_encoded[numerical_columns] = scaler.fit_transform(df_encoded[numerical_columns])\n",
    "\n",
    "# Split dataset into X and y\n",
    "X = df_encoded.drop('criticality_events', axis=1)\n",
    "y = df_encoded['criticality_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['value_counters_modules', 'identification_events',\n",
       "       'varnishLevelsTargetvolume', 'varnishLevelsTotalvolume',\n",
       "       'name_modules_Print Engine 1', 'name_modules_iFoil L',\n",
       "       'name_counters_modules_3D Varnish Counter',\n",
       "       'name_counters_modules_Foiled Pages Counter',\n",
       "       'name_counters_modules_Total Pages Counter', 'source_events_ICB n°1',\n",
       "       'source_events_ICB n°2', 'source_events_ICB n°4',\n",
       "       'source_events_ICB n°5', 'source_events_ICB n°6',\n",
       "       'source_events_ICB n°7', 'source_events_ICB n°8',\n",
       "       'source_events_Kernel', 'source_events_PLC', 'source_events_Pilot',\n",
       "       'source_events_RCB n°1', 'source_events_RCB n°2',\n",
       "       'source_events_RCB n°3', 'source_events_iFoil'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244083, 23)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences\n",
    "def create_sequences(X_data, y_data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(X_data) - seq_length):\n",
    "        x = X_data.iloc[i:(i + seq_length)].values\n",
    "        y = y_data.iloc[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Store the original index information for X_test and y_test\n",
    "X_test_index = X_test.index\n",
    "y_test_index = y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data into sequences of the specified length\n",
    "sequence_length = 1\n",
    "X_train, y_train = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test, y_test = create_sequences(X_test, y_test, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input schema\n",
    "input_schema = Schema([\n",
    "    TensorSpec(type=np.dtype(np.float64), shape=(-1, X_train.shape[1], X_train.shape[2]), name='input')\n",
    "])\n",
    "\n",
    "# Define the output schema\n",
    "output_schema = Schema([\n",
    "    ColSpec(type='integer', name='output')\n",
    "])\n",
    "\n",
    "# Create the signature\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40679, 1, 23)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203402, 1, 23)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('history2.pkl', 'wb') as f:\n",
    "#     pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the best mode\n",
    "# model = load_model('LTSM_model_1_93ACC/lstm_model.h5')\n",
    "\n",
    "# # Load the saved training history:\n",
    "# with open('LTSM_model_1_93ACC/history.pkl', 'rb') as f:\n",
    "#     history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# model_name = \"LSTM_predictive_maintenance\"\n",
    "# model_version = 1  # specify the version you want to load\n",
    "\n",
    "# model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "# loaded_model = mlflow.keras.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logged_model_1 = 'runs:/d1139ffad813474aa5e798007ee06db5/trained_model'\n",
    "# # Load model as a PyFuncModel.\n",
    "# loaded_model = mlflow.keras.load_model(logged_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logged_model_2 = 'runs:/a994f570d0794282bd87eb90b75f87cc/trained_model'\n",
    "# loaded_model_2 = mlflow.keras.load_model(logged_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_saved_model_directory' with the actual path to the saved_model.pb file\n",
    "logged_model = 'runs:/7e33dd8ce5104fc3b194f2c564f42202/trained_model'\n",
    "loaded_model = mlflow.keras.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x00000291AFD99960>\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model)\n",
    "# print(loaded_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 128)            77824     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1, 32)             12416     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 32)             0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142,835\n",
      "Trainable params: 142,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Predict on test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_prob \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred_prob, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Inverse transform the predictions and true labels\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred_prob = loaded_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Inverse transform the predictions and true labels\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy, classification report, and confusion matrix\n",
    "acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# Calculate loss score on test set\n",
    "loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test loss score\n",
    "print(f'Loss: {loss[0]}')\n",
    "\n",
    "acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(y_test_labels, y_pred_labels, output_dict=True)\n",
    "report_mlflow = classification_report(y_test_labels, y_pred_labels)\n",
    "\n",
    "# with open(\"classification_report.txt\", \"w\") as f:\n",
    "#     f.write(report_mlflow)\n",
    "\n",
    "# # Extract the metrics for the 'error' class\n",
    "# error_precision = report['ERROR']['precision']\n",
    "# error_recall = report['ERROR']['recall']\n",
    "# error_f1_score = report['ERROR']['f1-score']\n",
    "\n",
    "\n",
    "# # Log the metrics to MLflow\n",
    "# mlflow.log_metric('error_precision', error_precision)\n",
    "# mlflow.log_metric('error_recall', error_recall)\n",
    "# mlflow.log_metric('error_f1_score', error_f1_score)\n",
    "\n",
    "# # Log the classification report \n",
    "# mlflow.log_artifact('classification_report.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272/1272 [==============================] - 5s 4ms/step\n",
      "Accuracy: 0.7979055532338553\n",
      "Loss: 0.5716685056686401\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Inverse transform the predictions and true labels\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy, classification report, and confusion matrix\n",
    "acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# Calculate loss score on test set\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test loss score\n",
    "print(f'Loss: {loss[0]}')\n",
    "\n",
    "\n",
    "\n",
    "# Save confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "\n",
    "\n",
    "\n",
    "# Log the confusion matrix to MLflow\n",
    "mlflow.log_artifact('confusion_matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALLAN\\AppData\\Local\\Temp\\ipykernel_49516\\3544887439.py:9: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "C:\\Users\\ALLAN\\AppData\\Local\\Temp\\ipykernel_49516\\3544887439.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('training_and_validation_loss.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot accuracy from the loaded training history\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.savefig('training_and_validation_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_artifact('training_and_validation_loss.png')\n",
    "mlflow.log_artifact('training_and_validation_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'ERROR': 0, 'INFO': 1, 'WARNING': 2}\n"
     ]
    }
   ],
   "source": [
    "# Print class names and their corresponding numerical values\n",
    "class_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(\"Class mapping:\", class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALLAN\\AppData\\Local\\Temp\\ipykernel_49516\\2957229105.py:14: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Get the last 100 real and predicted values\n",
    "y_test_last50 = y_test_labels[-200:]\n",
    "y_pred_last50 = y_pred_labels[-200:]\n",
    "\n",
    "# Create a line chart to visualize the real and predicted values\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_last50, label='Real', marker='o')\n",
    "plt.plot(y_pred_last50, label='Predicted', marker='x')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Criticality Events')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Real and Predicted Criticality Events (Last 200)')\n",
    "plt.savefig('real_and_predicted.png')\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_artifact('real_and_predicted.png')\n",
    "\n",
    "# End MLflow tracking\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the start and end dates for the next week\n",
    "# start_date = X_test_index.max() + datetime.timedelta(days=1)\n",
    "# end_date = start_date + datetime.timedelta(weeks=1)\n",
    "\n",
    "# # Generate a date range for the next week at 10-second intervals\n",
    "# next_week_dates = pd.date_range(start=start_date, end=end_date, freq='10S')[:-1]\n",
    "\n",
    "\n",
    "# # Create a new DataFrame with the index set as the 'created_at' column\n",
    "# X_test_with_index = pd.DataFrame(X_test.reshape(X_test.shape[0], -1), columns=X.columns, index=X_test_index)\n",
    "\n",
    "# # Merge the new DataFrame with the original data\n",
    "# X_test_resampled = X_test_with_index.reset_index().merge(pd.DataFrame(index=next_week_dates), left_on='created_at', right_index=True, how='outer')\n",
    "\n",
    "# # Forward fill the missing data\n",
    "# X_test_resampled.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# # Drop the 'created_at' column\n",
    "# X_test_resampled.drop(columns=['created_at'], inplace=True)\n",
    "\n",
    "# # Resample y_test\n",
    "# y_test_resampled = y_test.reset_index().merge(pd.DataFrame(index=next_week_dates), left_on='created_at', right_index=True, how='outer')\n",
    "# y_test_resampled['created_at'] = pd.to_datetime(y_test_resampled['created_at'])  # Add this line\n",
    "# y_test_resampled.fillna(method='ffill', inplace=True)\n",
    "# y_test_resampled.drop(columns=['created_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the 'criticality_events' for the resampled X_test data\n",
    "# X_test_resampled_3D = X_test_resampled.values.reshape(X_test_resampled.shape[0], 1, X_test_resampled.shape[1])\n",
    "# y_pred_resampled = model.predict(X_test_resampled_3D)\n",
    "\n",
    "# # Convert the predicted probabilities to class labels\n",
    "# y_pred_resampled_labels = np.argmax(y_pred_resampled, axis=1)\n",
    "# y_pred_resampled_labels = le.inverse_transform(y_pred_resampled_labels)\n",
    "\n",
    "# # Truncate or extend the index to match the length of the predicted values\n",
    "# if len(next_week_dates) > len(y_pred_resampled_labels):\n",
    "#     next_week_dates = next_week_dates[:len(y_pred_resampled_labels)]\n",
    "# elif len(next_week_dates) < len(y_pred_resampled_labels):\n",
    "#     next_week_dates = pd.date_range(start=start_date, periods=len(y_pred_resampled_labels), freq='10S')\n",
    "\n",
    "# # Create a DataFrame with predicted labels and timestamps\n",
    "# y_pred_resampled_df = pd.DataFrame(y_pred_resampled_labels, columns=['predicted_criticality'], index=next_week_dates)\n",
    "\n",
    "# # Merge the true labels with the predicted labels\n",
    "# comparison_df = y_test_resampled.reset_index().rename(columns={'index': 'created_at'})\n",
    "# comparison_df['predicted_criticality'] = y_pred_resampled_labels\n",
    "# comparison_df.set_index('created_at', inplace=True)\n",
    "\n",
    "# # Rename the columns for better readability\n",
    "# comparison_df.columns = ['true_criticality', 'predicted_criticality']\n",
    "\n",
    "# plt.figure(figsize=(20, 6))\n",
    "# plt.plot(comparison_df.index, comparison_df['true_criticality'], label='True')\n",
    "# plt.plot(comparison_df.index, comparison_df['predicted_criticality'], label='Predicted', linestyle='--', alpha=0.7)\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Criticality Events')\n",
    "# plt.title('True vs. Predicted Criticality Events')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
