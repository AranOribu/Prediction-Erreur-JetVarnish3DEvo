{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de Classification detection d'anomalies (SVM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.floydhub.com/introduction-to-anomaly-detection-in-python/\n",
    "\n",
    "https://www.youtube.com/watch?v=c5V7gSTxS_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nom de fichier et chemin relatif\n",
    "filename = 'dataset_for_model.csv'\n",
    "path = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criticality_events</th>\n",
       "      <th>identification_events</th>\n",
       "      <th>value_counters_modules</th>\n",
       "      <th>varnishLevelsTargetvolume</th>\n",
       "      <th>varnishLevelsTotalvolume</th>\n",
       "      <th>name_modules_Print Engine 1</th>\n",
       "      <th>name_modules_iFoil L</th>\n",
       "      <th>name_counters_modules_3D Varnish Counter</th>\n",
       "      <th>name_counters_modules_Foiled Pages Counter</th>\n",
       "      <th>name_counters_modules_Total Pages Counter</th>\n",
       "      <th>...</th>\n",
       "      <th>source_events_ICB n°6</th>\n",
       "      <th>source_events_ICB n°7</th>\n",
       "      <th>source_events_ICB n°8</th>\n",
       "      <th>source_events_Kernel</th>\n",
       "      <th>source_events_PLC</th>\n",
       "      <th>source_events_Pilot</th>\n",
       "      <th>source_events_RCB n°1</th>\n",
       "      <th>source_events_RCB n°2</th>\n",
       "      <th>source_events_RCB n°3</th>\n",
       "      <th>source_events_iFoil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.389442</td>\n",
       "      <td>0.703951</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.389442</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   criticality_events  identification_events  value_counters_modules  \\\n",
       "0                   1               0.389442                0.703951   \n",
       "1                   1               0.389442                0.008983   \n",
       "\n",
       "   varnishLevelsTargetvolume  varnishLevelsTotalvolume  \\\n",
       "0                   0.304199                       1.0   \n",
       "1                   0.304199                       1.0   \n",
       "\n",
       "   name_modules_Print Engine 1  name_modules_iFoil L  \\\n",
       "0                          1.0                   0.0   \n",
       "1                          0.0                   1.0   \n",
       "\n",
       "   name_counters_modules_3D Varnish Counter  \\\n",
       "0                                       1.0   \n",
       "1                                       0.0   \n",
       "\n",
       "   name_counters_modules_Foiled Pages Counter  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "\n",
       "   name_counters_modules_Total Pages Counter  ...  source_events_ICB n°6  \\\n",
       "0                                        0.0  ...                    0.0   \n",
       "1                                        1.0  ...                    0.0   \n",
       "\n",
       "   source_events_ICB n°7  source_events_ICB n°8  source_events_Kernel  \\\n",
       "0                    0.0                    0.0                   0.0   \n",
       "1                    0.0                    0.0                   0.0   \n",
       "\n",
       "   source_events_PLC  source_events_Pilot  source_events_RCB n°1  \\\n",
       "0                1.0                  0.0                    0.0   \n",
       "1                0.0                  0.0                    0.0   \n",
       "\n",
       "   source_events_RCB n°2  source_events_RCB n°3  source_events_iFoil  \n",
       "0                    0.0                    0.0                  0.0  \n",
       "1                    0.0                    0.0                  1.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création d'un dataframe à partir du csv de données\n",
    "df_encoded = pd.read_csv(path+filename, index_col=0)\n",
    "df_encoded.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche la correspondance des codes de criticité avec leur label (stocké dans metrics_events_dict.json)\n",
    "# with open('../../data/metrics/metrics_events_dict.json', 'r') as data:\n",
    "#     criticalities = json.load(data).get('criticality encoded')\n",
    "# for value in df.criticality_events.unique():\n",
    "#     print(f'{value} : {criticalities.get(str(value))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input and output data\n",
    "X = df_encoded.drop(columns=['criticality_events']).values\n",
    "y = df_encoded['criticality_events'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diviser les données en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Scikit learn SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = clf.decision_function([[1]])\n",
    "dec.shape[1] # 4 classes: 4*3/2 = 6\n",
    "\n",
    "clf.decision_function_shape = \"ovr\"\n",
    "dec = clf.decision_function([[1]])\n",
    "dec.shape[1] # 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancier un modèle SVM\n",
    "#clf = svm.SVC(decision_function_shape='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuster le modèle aux données d'entraînement\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# évaluer le modèle sur l'ensemble de test\n",
    "#accuracy = clf.score(X_test, y_test)\n",
    "#print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;sgdclassifier&#x27;, SGDClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;sgdclassifier&#x27;, SGDClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier())])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "scaler = StandardScaler()\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "clf = make_pipeline(scaler, sgd_clf)\n",
    "#Pipeline(steps=[('standardscaler', scaler), ('sgdclassifier', sgd_clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('sgdclassifier', SGDClassifier())],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'sgdclassifier': SGDClassifier(),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'sgdclassifier__alpha': 0.0001,\n",
       " 'sgdclassifier__average': False,\n",
       " 'sgdclassifier__class_weight': None,\n",
       " 'sgdclassifier__early_stopping': False,\n",
       " 'sgdclassifier__epsilon': 0.1,\n",
       " 'sgdclassifier__eta0': 0.0,\n",
       " 'sgdclassifier__fit_intercept': True,\n",
       " 'sgdclassifier__l1_ratio': 0.15,\n",
       " 'sgdclassifier__learning_rate': 'optimal',\n",
       " 'sgdclassifier__loss': 'hinge',\n",
       " 'sgdclassifier__max_iter': 1000,\n",
       " 'sgdclassifier__n_iter_no_change': 5,\n",
       " 'sgdclassifier__n_jobs': None,\n",
       " 'sgdclassifier__penalty': 'l2',\n",
       " 'sgdclassifier__power_t': 0.5,\n",
       " 'sgdclassifier__random_state': None,\n",
       " 'sgdclassifier__shuffle': True,\n",
       " 'sgdclassifier__tol': 0.001,\n",
       " 'sgdclassifier__validation_fraction': 0.1,\n",
       " 'sgdclassifier__verbose': 0,\n",
       " 'sgdclassifier__warm_start': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow tracking\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the model's parameters\n",
    "# mlflow.log_param('sequence_length', sequence_length)\n",
    "# mlflow.log_param('batch_size', batch_size)\n",
    "# mlflow.log_param('epochs', epochs)\n",
    "# mlflow.log_param('learning_rate', learning_rate)\n",
    "# mlflow.log_param('early_stopping_patience', patience)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stop, checkpoint],\n",
    "                    shuffle=False)\n",
    "                    \n",
    "history = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the final training loss and accuracy\n",
    "train_loss = history.history['loss'][-1]\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "mlflow.log_metric('train_loss', train_loss)\n",
    "mlflow.log_metric('train_accuracy', train_accuracy)\n",
    "\n",
    "# Log the final validation loss and accuracy\n",
    "val_loss = history.history['val_loss'][-1]\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "mlflow.log_metric('val_loss', val_loss)\n",
    "mlflow.log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model with the schema\n",
    "mlflow.keras.log_model(model, 'trained_model', signature=signature)\n",
    "\n",
    "# Save the encoders and normalizer\n",
    "joblib.dump(ohe, 'ohe.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "mlflow.log_artifact('ohe.pkl')\n",
    "mlflow.log_artifact('scaler.pkl')\n",
    "\n",
    "# Log the example input JSON file as an artifact\n",
    "mlflow.log_artifact(\"example_input.json\")\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Inverse transform the predictions and true labels\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy, classification report, and confusion matrix\n",
    "acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# Calculate loss score on test set\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test loss score\n",
    "print(f'Loss: {loss[0]}')\n",
    "\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(y_test_labels, y_pred_labels, output_dict=True)\n",
    "\n",
    "\n",
    "with open(\"classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Extract the metrics for the 'error' class\n",
    "error_precision = report['ERROR']['precision']\n",
    "error_recall = report['ERROR']['recall']\n",
    "error_f1_score = report['ERROR']['f1-score']\n",
    "\n",
    "\n",
    "# Log the metrics to MLflow\n",
    "mlflow.log_metric('error_precision', error_precision)\n",
    "mlflow.log_metric('error_recall', error_recall)\n",
    "mlflow.log_metric('error_f1_score', error_f1_score)\n",
    "\n",
    "# Log the classification report \n",
    "mlflow.log_artifact('classification_report.txt')\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Inverse transform the predictions and true labels\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print accuracy, classification report, and confusion matrix\n",
    "acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f'Accuracy: {acc}')\n",
    "\n",
    "# Calculate loss score on test set\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test loss score\n",
    "print(f'Loss: {loss[0]}')\n",
    "\n",
    "\n",
    "\n",
    "# Save confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "\n",
    "\n",
    "\n",
    "# Log the confusion matrix to MLflow\n",
    "mlflow.log_artifact('classification_report.txt')\n",
    "mlflow.log_artifact('confusion_matrix.png')\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('training_and_validation_loss.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot accuracy from the loaded training history\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.savefig('training_and_validation_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_artifact('training_and_validation_loss.png')\n",
    "mlflow.log_artifact('training_and_validation_accuracy.png')\n",
    "\n",
    "# Print class names and their corresponding numerical values\n",
    "class_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(\"Class mapping:\", class_mapping)\n",
    "\n",
    "# Get the last 100 real and predicted values\n",
    "y_test_last50 = y_test_labels[-200:]\n",
    "y_pred_last50 = y_pred_labels[-200:]\n",
    "\n",
    "# Create a line chart to visualize the real and predicted values\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_last50, label='Real', marker='o')\n",
    "plt.plot(y_pred_last50, label='Predicted', marker='x')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Criticality Events')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Real and Predicted Criticality Events (Last 200)')\n",
    "plt.savefig('real_and_predicted.png')\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_artifact('real_and_predicted.png')\n",
    "\n",
    "# End MLflow tracking\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      " [[683460      0      0      0]\n",
      " [     0  13223    379      0]\n",
      " [     0    895   1627      0]\n",
      " [     0   1701    461    341]]\n",
      "\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    683460\n",
      "           1       0.84      0.97      0.90     13602\n",
      "           2       0.66      0.65      0.65      2522\n",
      "           3       1.00      0.14      0.24      2503\n",
      "\n",
      "    accuracy                           1.00    702087\n",
      "   macro avg       0.87      0.69      0.70    702087\n",
      "weighted avg       1.00      1.00      0.99    702087\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRapport de classification :\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, classification_report(y_test, y_pred))\n\u001b[0;32m     42\u001b[0m \u001b[39m# Afficher les meilleurs paramètres trouvés\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMeilleurs paramètres trouvés :\u001b[39m\u001b[39m\"\u001b[39m, clf\u001b[39m.\u001b[39;49mbest_params_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn import svm\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import mlflow\n",
    "\n",
    "# # Diviser les données en ensembles de formation et de test\n",
    "# #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Définir les paramètres du modèle\n",
    "# parameters = {\"C\": [1,10], \"kernel\": (\"linear\",\"rbf\"), \"gamma\": \"scale\"}\n",
    "\n",
    "# # Débuter le suivi MLflow\n",
    "# mlflow.start_run()\n",
    "\n",
    "# # Instancier un modèle SVM avec les paramètres définis\n",
    "# svc = svm.SVC(decision_function_shape=\"ovo\")\n",
    "\n",
    "# # Effectuer une recherche de grille pour trouver les meilleurs paramètres\n",
    "# clf = GridSearchCV(svc, parameters, cv=5)\n",
    "\n",
    "# # Entraîner le modèle et obtenir la précision\n",
    "# svc.fit(X_train, y_train)\n",
    "\n",
    "# # Prédire les classes pour les données de test\n",
    "# y_pred = svc.predict(X_test)\n",
    "\n",
    "# # Obtenir la précision du modèle pour l'ensemble de test\n",
    "# accuracy_clf_svm = svc.score(X_test, y_test)\n",
    "\n",
    "# # Enregistrer les paramètres et la précision dans MLflow\n",
    "# mlflow.log_params(parameters)\n",
    "# mlflow.log_metric(\"accuracy\", accuracy_clf_svm)\n",
    "\n",
    "# # Terminer le suivi MLflow\n",
    "# mlflow.end_run()\n",
    "\n",
    "# # Afficher la matrice de confusion et le rapport de classification\n",
    "# print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred))\n",
    "# print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# # Afficher les meilleurs paramètres trouvés\n",
    "# print(\"\\nMeilleurs paramètres trouvés :\", clf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2315c9af7dedaeb0b2bf51504304a927c605b523f04dad98936c50abe500b408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
