{"Logistic Regression": {"model__C": [0.01, 0.1, 1.0, 10.0, 100.0], "model__penalty": ["l2", "none"], "model__max_iter": [100, 200, 300]}, "Random Forest Classifier": {"model__n_estimators": [25, 50, 100, 150], "model__max_depth": [null, 10, 20, 30], "model__min_samples_split": [2, 5, 10], "model__min_samples_leaf": [1, 2, 4], "model__max_features": ["auto", "sqrt", "log2"]}, "XGB Classifier": {"model__n_estimators": [100, 200, 300, 400], "model__learning_rate": [0.01, 0.05, 0.1, 0.2], "model__max_depth": [3, 4, 5, 6]}, "LGBM Classifier": {"model__n_estimators": [100, 200, 300, 400], "model__learning_rate": [0.01, 0.05, 0.1, 0.2], "model__num_leaves": [31, 41, 51, 61]}, "Decision Tree": {"model__criterion": ["gini", "entropy"], "model__max_depth": [null, 2, 4, 6, 8, 10], "model__min_samples_split": [2, 5, 10], "model__min_samples_leaf": [1, 2, 4]}, "Gradient Boosting Classifier": {"model__n_estimators": [100, 200, 300, 400], "model__learning_rate": [0.01, 0.05, 0.1, 0.2], "model__max_depth": [3, 5, 7]}, "Naive Bayes": {"model__var_smoothing": [1e-09, 1e-08, 1e-07, 1e-06]}}