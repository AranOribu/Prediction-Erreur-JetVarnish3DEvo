{"description": "Le meilleur mod\u00e8le de prediction de criticit\u00e9 du run est lgbm avec un recall de 0.673", "params": {"memory": "None", "steps": "[('scaler', StandardScaler()), ('model', LGBMClassifier(learning_rate=0.2, n_estimators=300))]", "verbose": "False", "scaler": "StandardScaler()", "model": "LGBMClassifier(learning_rate=0.2, n_estimators=300)", "scaler__copy": "True", "scaler__with_mean": "True", "scaler__with_std": "True", "model__boosting_type": "gbdt", "model__class_weight": "None", "model__colsample_bytree": "1.0", "model__importance_type": "split", "model__learning_rate": "0.2", "model__max_depth": "-1", "model__min_child_samples": "20", "model__min_child_weight": "0.001", "model__min_split_gain": "0.0", "model__n_estimators": "300", "model__n_jobs": "-1", "model__num_leaves": "31", "model__objective": "None", "model__random_state": "None", "model__reg_alpha": "0.0", "model__reg_lambda": "0.0", "model__silent": "warn", "model__subsample": "1.0", "model__subsample_for_bin": "200000", "model__subsample_freq": "0"}, "params_type": "{'lr': {'model': LogisticRegression(), 'params': {'model__C': [0.1, 1.0, 10.0]}}, 'rf': {'model': RandomForestClassifier(), 'params': {'model__n_estimators': [25, 50, 100], 'model__max_depth': [None, 10, 20], 'model__min_samples_split': [2, 5, 10], 'model__min_samples_leaf': [1, 2, 4]}}, 'svc': {'model': SVC(probability=True), 'params': {'model__C': [0.1, 1.0, 10.0], 'model__gamma': [0.1, 1.0, 10.0]}}, 'xgb': {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              predictor=None, random_state=None, ...), 'params': {'model__n_estimators': [100, 200, 300], 'model__learning_rate': [0.01, 0.1, 0.2]}}, 'lgbm': {'model': LGBMClassifier(), 'params': {'model__n_estimators': [100, 200, 300], 'model__learning_rate': [0.01, 0.1, 0.2]}}, 'dt': {'model': DecisionTreeClassifier(), 'params': {'model__criterion': ['gini', 'entropy'], 'model__max_depth': [None, 2, 4, 6, 8, 10], 'model__min_samples_split': [2, 5, 10], 'model__min_samples_leaf': [1, 2, 4]}}, 'gbc': {'model': GradientBoostingClassifier(), 'params': {'model__n_estimators': [100, 200, 300], 'model__learning_rate': [0.01, 0.1, 0.2], 'model__max_depth': [1, 3, 5]}}, 'nb': {'model': GaussianNB(), 'params': {'model__var_smoothing': [1e-09, 1e-07]}}} (indique la cat\u00e9gorie de param\u00e8tres utilis\u00e9e : 'heavy', 'medium', 'light', ou 'test'. 'Heavy' implique un grand nombre de param\u00e8tres, 'medium' un nombre mod\u00e9r\u00e9, 'light' un nombre restreint, tandis que 'test' d\u00e9signe des mod\u00e8les et hyperparam\u00e8tres simplifi\u00e9s pour des tests rapides du pipeline)", "scaler used": "StandardScaler a \u00e9t\u00e9 utilis\u00e9 sur ce run pour standardiser les donn\u00e9es de type num\u00e9rique", "sampling_info": "Sur-\u00e9chantillonnage r\u00e9alis\u00e9 pour \u00e9quilibrer les classes. Distribution initiale : INFO: 26231, ERROR: 26231, NO_EVENT: 25557, WARNING: 12970. Chaque classe a \u00e9t\u00e9 r\u00e9duite \u00e0 12970 \u00e9chantillons, correspondant au nombre dans la classe 'WARNING'. Les classes 'INFO', 'NO_EVENT' et 'WARNING' ont \u00e9t\u00e9 fusionn\u00e9es en une classe 'FALSE' (pas d'erreur), et la classe 'ERROR' a \u00e9t\u00e9 renomm\u00e9e 'TRUE' (erreur), r\u00e9sultant en deux nouvelles classes \u00e9quilibr\u00e9es : 'TRUE': 21007 et 'FALSE': 51784 (51784 pour les 2 classes avec SMOTE pour le jeu d'entrainement)", "test_size_pourcentage": 0.15, "X_train_sampling": "103568", "y_train_sampling": "103568", "X_test_sampling": "18198", "y_test_sampling": "18198", "gridsearch_details": {"cv": 5, "scoring_metric": "recall"}, "learningcurve_details": {"cv": 5, "scoring_metric": "recall"}, "params_choice": "medium", "miscellaneous note": ""}